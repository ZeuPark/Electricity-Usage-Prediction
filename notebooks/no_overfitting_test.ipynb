{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9f327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic' # 한글 폰트 설정\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import torch #cuda용 \n",
    "import warnings # 경고 메시지 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56eebd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능: True\n",
      "PyTorch CUDA 버전: 11.8\n",
      "GPU 이름: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"PyTorch CUDA 버전: {torch.version.cuda}\")\n",
    "    print(f\"GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CPU 버전이 설치됨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ca0fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "building = pd.read_csv('../data/building_info.csv')\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735f71c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>건물번호</th>\n",
       "      <th>건물유형</th>\n",
       "      <th>연면적(m2)</th>\n",
       "      <th>냉방면적(m2)</th>\n",
       "      <th>태양광용량(kW)</th>\n",
       "      <th>ESS저장용량(kWh)</th>\n",
       "      <th>PCS용량(kW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>호텔</td>\n",
       "      <td>82912.71</td>\n",
       "      <td>77586.00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>상용</td>\n",
       "      <td>40658.90</td>\n",
       "      <td>30392.82</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>병원</td>\n",
       "      <td>560431.00</td>\n",
       "      <td>418992.00</td>\n",
       "      <td>278.58</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>호텔</td>\n",
       "      <td>41813.29</td>\n",
       "      <td>23715.71</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>학교</td>\n",
       "      <td>403749.39</td>\n",
       "      <td>248507.00</td>\n",
       "      <td>1983.05</td>\n",
       "      <td>1025</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   건물번호 건물유형    연면적(m2)   냉방면적(m2) 태양광용량(kW) ESS저장용량(kWh) PCS용량(kW)\n",
       "0     1   호텔   82912.71   77586.00         -            -         -\n",
       "1     2   상용   40658.90   30392.82         -            -         -\n",
       "2     3   병원  560431.00  418992.00    278.58            -         -\n",
       "3     4   호텔   41813.29   23715.71         -            -         -\n",
       "4     5   학교  403749.39  248507.00   1983.05         1025       250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22df9715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   건물번호          100 non-null    int64  \n",
      " 1   건물유형          100 non-null    object \n",
      " 2   연면적(m2)       100 non-null    float64\n",
      " 3   냉방면적(m2)      100 non-null    float64\n",
      " 4   태양광용량(kW)     100 non-null    object \n",
      " 5   ESS저장용량(kWh)  100 non-null    object \n",
      " 6   PCS용량(kW)     100 non-null    object \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 5.6+ KB\n"
     ]
    }
   ],
   "source": [
    "building.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c42fd47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>건물번호</th>\n",
       "      <th>일시</th>\n",
       "      <th>기온(°C)</th>\n",
       "      <th>강수량(mm)</th>\n",
       "      <th>풍속(m/s)</th>\n",
       "      <th>습도(%)</th>\n",
       "      <th>일조(hr)</th>\n",
       "      <th>일사(MJ/m2)</th>\n",
       "      <th>전력소비량(kWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20240601 00</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 00</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5794.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20240601 01</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 01</td>\n",
       "      <td>18.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5591.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20240601 02</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 02</td>\n",
       "      <td>18.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5338.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20240601 03</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 03</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4554.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20240601 04</td>\n",
       "      <td>1</td>\n",
       "      <td>20240601 04</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3602.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_date_time  건물번호           일시  기온(°C)  강수량(mm)  풍속(m/s)  습도(%)  일조(hr)  \\\n",
       "0  1_20240601 00     1  20240601 00    18.3      0.0      2.6   82.0     0.0   \n",
       "1  1_20240601 01     1  20240601 01    18.3      0.0      2.7   82.0     0.0   \n",
       "2  1_20240601 02     1  20240601 02    18.1      0.0      2.6   80.0     0.0   \n",
       "3  1_20240601 03     1  20240601 03    18.0      0.0      2.6   81.0     0.0   \n",
       "4  1_20240601 04     1  20240601 04    17.8      0.0      1.3   81.0     0.0   \n",
       "\n",
       "   일사(MJ/m2)  전력소비량(kWh)  \n",
       "0        0.0     5794.80  \n",
       "1        0.0     5591.85  \n",
       "2        0.0     5338.17  \n",
       "3        0.0     4554.42  \n",
       "4        0.0     3602.25  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17c1b614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 204000 entries, 0 to 203999\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   num_date_time  204000 non-null  object \n",
      " 1   건물번호           204000 non-null  int64  \n",
      " 2   일시             204000 non-null  object \n",
      " 3   기온(°C)         204000 non-null  float64\n",
      " 4   강수량(mm)        204000 non-null  float64\n",
      " 5   풍속(m/s)        204000 non-null  float64\n",
      " 6   습도(%)          204000 non-null  float64\n",
      " 7   일조(hr)         204000 non-null  float64\n",
      " 8   일사(MJ/m2)      204000 non-null  float64\n",
      " 9   전력소비량(kWh)     204000 non-null  float64\n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 15.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8121ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_date_time</th>\n",
       "      <th>건물번호</th>\n",
       "      <th>일시</th>\n",
       "      <th>기온(°C)</th>\n",
       "      <th>강수량(mm)</th>\n",
       "      <th>풍속(m/s)</th>\n",
       "      <th>습도(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_20240825 00</td>\n",
       "      <td>1</td>\n",
       "      <td>20240825 00</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_20240825 01</td>\n",
       "      <td>1</td>\n",
       "      <td>20240825 01</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_20240825 02</td>\n",
       "      <td>1</td>\n",
       "      <td>20240825 02</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_20240825 03</td>\n",
       "      <td>1</td>\n",
       "      <td>20240825 03</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_20240825 04</td>\n",
       "      <td>1</td>\n",
       "      <td>20240825 04</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_date_time  건물번호           일시  기온(°C)  강수량(mm)  풍속(m/s)  습도(%)\n",
       "0  1_20240825 00     1  20240825 00    26.5      0.0      0.7   80.0\n",
       "1  1_20240825 01     1  20240825 01    26.1      0.0      0.0   80.0\n",
       "2  1_20240825 02     1  20240825 02    25.9      0.0      0.3   83.0\n",
       "3  1_20240825 03     1  20240825 03    25.7      0.0      1.1   83.0\n",
       "4  1_20240825 04     1  20240825 04    25.5      0.0      1.0   86.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af56cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_train'] = 1\n",
    "test['is_train'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf1fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['일조(hr)', '일사(MJ/m2)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88505530",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "766c690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 크기: (220800, 9)\n",
      "train 데이터 개수: 204000\n",
      "test 데이터 개수: 16800\n"
     ]
    }
   ],
   "source": [
    "print(f\"전체 데이터 크기: {combined.shape}\")\n",
    "print(f\"train 데이터 개수: {combined[combined['is_train']==1].shape[0]}\")\n",
    "print(f\"test 데이터 개수: {combined[combined['is_train']==0].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bb02f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220800 entries, 0 to 220799\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   num_date_time  220800 non-null  object \n",
      " 1   건물번호           220800 non-null  int64  \n",
      " 2   일시             220800 non-null  object \n",
      " 3   기온(°C)         220800 non-null  float64\n",
      " 4   강수량(mm)        220800 non-null  float64\n",
      " 5   풍속(m/s)        220800 non-null  float64\n",
      " 6   습도(%)          220800 non-null  float64\n",
      " 7   전력소비량(kWh)     204000 non-null  float64\n",
      " 8   is_train       220800 non-null  int64  \n",
      "dtypes: float64(5), int64(2), object(2)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cd5f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    \"\"\"SMAPE 계산 함수\"\"\"\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def time_features(data):\n",
    "    \"\"\"시간 관련 피처 생성\"\"\"\n",
    "    date = pd.to_datetime(data['일시'])\n",
    "    \n",
    "    data['hour'] = date.dt.hour\n",
    "    data['dow'] = date.dt.weekday\n",
    "    data['month'] = date.dt.month\n",
    "    data['week'] = date.dt.isocalendar().week.astype(np.int32)\n",
    "    data['day'] = date.dt.day\n",
    "    \n",
    "    # 순환적 시간 변수\n",
    "    data['sin_time'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
    "    data['cos_time'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
    "    \n",
    "    # 휴일 변수 (주말: 1, 평일: 0)\n",
    "    data['holiday'] = data.apply(lambda x: 0 if x['dow'] < 5 else 1, axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def weather_features(data):\n",
    "    \"\"\"기상 관련 복합 지수 계산\"\"\"\n",
    "    # THI (Temperature-Humidity Index): 체감온도 지수\n",
    "    data['THI'] = 9/5*data['기온(°C)'] - 0.55*(1-data['습도(%)']/100)*(9/5*data['습도(%)'] - 26) + 32\n",
    "    \n",
    "    # WC (Wind Chill): 풍속냉각지수\n",
    "    data['WC'] = 13.12 + 0.6215*data['기온(°C)'] - 13.947*data['풍속(m/s)']**0.16 + 0.486*data['기온(°C)']*data['풍속(m/s)']**0.16\n",
    "    \n",
    "    # 강수량이 있는 시점 표시\n",
    "    data['weather'] = (data['강수량(mm)'] > 0).astype(int)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def temp_stats_features(data):\n",
    "    \"\"\"온도 통계 피처 생성\"\"\"\n",
    "    # 건물별, 일별 온도 통계\n",
    "    daily_stats = data.groupby(['건물번호', 'day', 'month'])['기온(°C)'].agg(['mean', 'max', 'min']).reset_index()\n",
    "    daily_stats.columns = ['건물번호', 'day', 'month', 'avg_temp', 'max_temp', 'min_temp']\n",
    "    daily_stats['temp_diff'] = daily_stats['max_temp'] - daily_stats['min_temp']\n",
    "    \n",
    "    data = pd.merge(data, daily_stats, on=['건물번호', 'day', 'month'], how='left')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def power_stats_features(train_data, test_data):\n",
    "    \"\"\"과거 전력 사용량 통계 피처 생성\"\"\"\n",
    "    # 건물별, 시간별, 요일별 평균\n",
    "    power_stats = train_data.groupby(['건물번호', 'hour', 'dow'])['전력소비량(kWh)'].agg(['mean', 'std']).reset_index()\n",
    "    power_stats.columns = ['건물번호', 'hour', 'dow', 'power_hour_dow_mean', 'power_hour_dow_std']\n",
    "    \n",
    "    train_data = pd.merge(train_data, power_stats, on=['건물번호', 'hour', 'dow'], how='left')\n",
    "    test_data = pd.merge(test_data, power_stats, on=['건물번호', 'hour', 'dow'], how='left')\n",
    "    \n",
    "    # 건물별, 시간별, 휴일별 평균\n",
    "    power_holiday_stats = train_data.groupby(['건물번호', 'hour', 'holiday'])['전력소비량(kWh)'].agg(['mean', 'std']).reset_index()\n",
    "    power_holiday_stats.columns = ['건물번호', 'hour', 'holiday', 'power_holiday_mean', 'power_holiday_std']\n",
    "    \n",
    "    train_data = pd.merge(train_data, power_holiday_stats, on=['건물번호', 'hour', 'holiday'], how='left')\n",
    "    test_data = pd.merge(test_data, power_holiday_stats, on=['건물번호', 'hour', 'holiday'], how='left')\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "def feature_engineering(data, is_train=True):\n",
    "    \"\"\"전체 피처 엔지니어링 파이프라인\"\"\"\n",
    "    # 결측치 처리\n",
    "    data = data.fillna(method='ffill').fillna(0)\n",
    "    \n",
    "    # 피처 생성\n",
    "    data = time_features(data)\n",
    "    data = weather_features(data)\n",
    "    data = temp_stats_features(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96f9659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_models():\n",
    "    \"\"\"GPU 사용 모델 정의\"\"\"\n",
    "    models = {\n",
    "        'XGBoost': xgb.XGBRegressor(\n",
    "            n_estimators=1000,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            tree_method='gpu_hist',\n",
    "            gpu_id=0,\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        ),\n",
    "        'LightGBM': lgb.LGBMRegressor(\n",
    "            n_estimators=1000,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=0.1,\n",
    "            device='gpu',\n",
    "            random_state=42,\n",
    "            verbose=-1\n",
    "        ),\n",
    "        'CatBoost': cb.CatBoostRegressor(\n",
    "            iterations=500,\n",
    "            depth=6,\n",
    "            learning_rate=0.1,\n",
    "            l2_leaf_reg=3,\n",
    "            task_type='GPU',\n",
    "            random_state=42,\n",
    "            verbose=False\n",
    "        )\n",
    "    }\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2011797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_validation_models(X_train, y_train):\n",
    "    \"\"\"KFold 교차검증으로 모델 성능 평가\"\"\"\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = {model_name: [] for model_name in get_models().keys()}\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "        print(f\"\\n=== Fold {fold+1}/5 ===\")\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        models = get_models()\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            print(f\"{model_name} 학습중...\")\n",
    "            model.fit(X_tr, y_tr)\n",
    "            pred = model.predict(X_val)\n",
    "            score = smape(y_val, pred)\n",
    "            results[model_name].append(score)\n",
    "            print(f\"{model_name} SMAPE: {score:.4f}\")\n",
    "    \n",
    "    print(\"\\n=== 최종 결과 ===\")\n",
    "    for model_name, scores in results.items():\n",
    "        print(f\"{model_name} - 평균: {np.mean(scores):.4f}, 표준편차: {np.std(scores):.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def train_individual_building_models(train_data, test_data, feature_cols):\n",
    "    \"\"\"건물별 개별 모델 학습\"\"\"\n",
    "    building_predictions = {}\n",
    "    building_scores = []\n",
    "    \n",
    "    for building_num in tqdm(range(1, 101), desc=\"건물별 모델 학습\"):\n",
    "        # 해당 건물 데이터 추출\n",
    "        building_train = train_data[train_data['건물번호'] == building_num].copy()\n",
    "        building_test = test_data[test_data['건물번호'] == building_num].copy()\n",
    "        \n",
    "        if len(building_train) == 0:\n",
    "            continue\n",
    "            \n",
    "        # 피처와 타겟 분리\n",
    "        X = building_train[feature_cols]\n",
    "        y = building_train['전력소비량(kWh)']\n",
    "        X_test = building_test[feature_cols]\n",
    "        \n",
    "        # train/validation 분할 (시계열 특성 고려)\n",
    "        split_point = int(len(X) * 0.8)\n",
    "        X_train_b, X_val_b = X[:split_point], X[split_point:]\n",
    "        y_train_b, y_val_b = y[:split_point], y[split_point:]\n",
    "        \n",
    "        # XGBoost 모델 학습\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train_b, y_train_b)\n",
    "        \n",
    "        # 검증 점수 계산\n",
    "        val_pred = model.predict(X_val_b)\n",
    "        score = smape(y_val_b, val_pred)\n",
    "        building_scores.append(score)\n",
    "        \n",
    "        # 테스트 예측\n",
    "        test_pred = model.predict(X_test)\n",
    "        building_predictions[building_num] = test_pred\n",
    "    \n",
    "    print(f\"\\n건물별 모델 평균 SMAPE: {np.mean(building_scores):.4f}\")\n",
    "    \n",
    "    return building_predictions, building_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1f2eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_ensemble_pipeline(combined_data, drop_cols):\n",
    "    \"\"\"고급 앙상블 + 메타모델 + 슈퍼메타피쳐 파이프라인\"\"\"\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # GPU 사용 확인\n",
    "    print(\"=== GPU 사용 확인 ===\")\n",
    "    try:\n",
    "        # XGBoost GPU 확인\n",
    "        import xgboost as xgb\n",
    "        print(f\"XGBoost version: {xgb.__version__}\")\n",
    "        \n",
    "        # LightGBM GPU 확인\n",
    "        import lightgbm as lgb\n",
    "        print(f\"LightGBM version: {lgb.__version__}\")\n",
    "        \n",
    "        # CatBoost GPU 확인\n",
    "        import catboost as cb\n",
    "        print(f\"CatBoost version: {cb.__version__}\")\n",
    "        \n",
    "        # CUDA 사용 가능 확인\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "        else:\n",
    "            print(\"CUDA not available - falling back to CPU\")\n",
    "    except Exception as e:\n",
    "        print(f\"GPU 확인 중 오류: {e}\")\n",
    "    \n",
    "    # 1. 데이터 분리 및 기본 피처 엔지니어링\n",
    "    print(\"=== 1단계: 데이터 준비 ===\")\n",
    "    train_data = combined_data[combined_data['is_train']==1].copy()\n",
    "    test_data = combined_data[combined_data['is_train']==0].copy()\n",
    "    \n",
    "    train_data = feature_engineering(train_data, is_train=True)\n",
    "    test_data = feature_engineering(test_data, is_train=False)\n",
    "    train_data, test_data = power_stats_features(train_data, test_data)\n",
    "    \n",
    "    feature_cols = [col for col in train_data.columns if col not in drop_cols and col != '전력소비량(kWh)']\n",
    "    print(f\"기본 피처 수: {len(feature_cols)}\")\n",
    "    \n",
    "    # 2. Level 1: GPU 모델들 (5-fold)\n",
    "    print(\"\\n=== 2단계: Level 1 모델 학습 ===\")\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # GPU 모델들 가져오기 (GPU 설정 강화)\n",
    "    gpu_models = get_models()\n",
    "    \n",
    "    # GPU 설정 검증 및 강화\n",
    "    try:\n",
    "        # XGBoost GPU 설정 검증\n",
    "        if hasattr(gpu_models['XGBoost'], 'tree_method'):\n",
    "            print(f\"XGBoost tree_method: {gpu_models['XGBoost'].tree_method}\")\n",
    "        \n",
    "        # LightGBM GPU 설정 검증  \n",
    "        if hasattr(gpu_models['LightGBM'], 'device'):\n",
    "            print(f\"LightGBM device: {gpu_models['LightGBM'].device}\")\n",
    "            \n",
    "        # CatBoost GPU 설정 검증\n",
    "        if hasattr(gpu_models['CatBoost'], 'task_type'):\n",
    "            print(f\"CatBoost task_type: {gpu_models['CatBoost'].task_type}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"GPU 모델 설정 확인 중 오류: {e}\")\n",
    "    \n",
    "    level1_models = {\n",
    "        'xgb': gpu_models['XGBoost'],\n",
    "        'lgb': gpu_models['LightGBM'], \n",
    "        'cat': gpu_models['CatBoost'],\n",
    "        'rf': RandomForestRegressor(n_estimators=200, max_depth=8, random_state=42, n_jobs=-1)\n",
    "    }\n",
    "    \n",
    "    # Level 1 예측값 저장용\n",
    "    oof_predictions = pd.DataFrame(index=train_data.index)\n",
    "    test_predictions = pd.DataFrame()\n",
    "    \n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data['전력소비량(kWh)']\n",
    "    X_test = test_data[feature_cols]\n",
    "    \n",
    "    for name, model in level1_models.items():\n",
    "        print(f\"Learning {name}...\")\n",
    "        oof_pred = np.zeros(len(X_train))\n",
    "        test_pred = np.zeros(len(X_test))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            model.fit(X_tr, y_tr)\n",
    "            oof_pred[val_idx] = model.predict(X_val)\n",
    "            test_pred += model.predict(X_test) / 5\n",
    "        \n",
    "        oof_predictions[f'{name}_pred'] = oof_pred\n",
    "        test_predictions[f'{name}_pred'] = test_pred\n",
    "        \n",
    "        score = smape(y_train, oof_pred)\n",
    "        print(f\"{name} SMAPE: {score:.4f}\")\n",
    "    \n",
    "    # 3. Level 1 앙상블 점수\n",
    "    ensemble_pred = oof_predictions.mean(axis=1)\n",
    "    ensemble_score = smape(y_train, ensemble_pred)\n",
    "    print(f\"\\nLevel 1 앙상블 SMAPE: {ensemble_score:.4f}\")\n",
    "    \n",
    "    # 4. 슈퍼메타피쳐 생성\n",
    "    print(\"\\n=== 3단계: 슈퍼메타피쳐 생성 ===\")\n",
    "    \n",
    "    # 예측값 통계 피쳐\n",
    "    oof_predictions['pred_mean'] = oof_predictions.mean(axis=1)\n",
    "    oof_predictions['pred_std'] = oof_predictions.std(axis=1)\n",
    "    oof_predictions['pred_max'] = oof_predictions.max(axis=1)\n",
    "    oof_predictions['pred_min'] = oof_predictions.min(axis=1)\n",
    "    oof_predictions['pred_range'] = oof_predictions['pred_max'] - oof_predictions['pred_min']\n",
    "    \n",
    "    test_predictions['pred_mean'] = test_predictions.mean(axis=1)\n",
    "    test_predictions['pred_std'] = test_predictions.std(axis=1)\n",
    "    test_predictions['pred_max'] = test_predictions.max(axis=1)\n",
    "    test_predictions['pred_min'] = test_predictions.min(axis=1)\n",
    "    test_predictions['pred_range'] = test_predictions['pred_max'] - test_predictions['pred_min']\n",
    "    \n",
    "    # 건물별 예측 패턴 피쳐\n",
    "    building_meta_train = []\n",
    "    building_meta_test = []\n",
    "    \n",
    "    for building_num in range(1, 101):\n",
    "        # Train 건물별 메타피쳐\n",
    "        building_mask_train = train_data['건물번호'] == building_num\n",
    "        if building_mask_train.sum() > 0:\n",
    "            building_preds = oof_predictions[building_mask_train]\n",
    "            building_meta = {\n",
    "                'building_pred_volatility': building_preds.std(axis=0).mean(),\n",
    "                'building_pred_consistency': 1 / (building_preds.std(axis=1).mean() + 1e-8),\n",
    "                'building_pred_bias': building_preds.mean(axis=1).std()\n",
    "            }\n",
    "            building_meta_train.extend([building_meta] * building_mask_train.sum())\n",
    "        \n",
    "        # Test 건물별 메타피쳐  \n",
    "        building_mask_test = test_data['건물번호'] == building_num\n",
    "        if building_mask_test.sum() > 0:\n",
    "            building_test_preds = test_predictions[building_mask_test]\n",
    "            building_meta = {\n",
    "                'building_pred_volatility': building_test_preds.std(axis=0).mean() if len(building_test_preds) > 0 else 0,\n",
    "                'building_pred_consistency': 1 / (building_test_preds.std(axis=1).mean() + 1e-8) if len(building_test_preds) > 0 else 1,\n",
    "                'building_pred_bias': building_test_preds.mean(axis=1).std() if len(building_test_preds) > 0 else 0\n",
    "            }\n",
    "            building_meta_test.extend([building_meta] * building_mask_test.sum())\n",
    "    \n",
    "    # 메타피쳐 DataFrame으로 변환\n",
    "    building_meta_train_df = pd.DataFrame(building_meta_train, index=train_data.index)\n",
    "    building_meta_test_df = pd.DataFrame(building_meta_test, index=test_data.index)\n",
    "    \n",
    "    # 5. Level 2: 메타모델 학습\n",
    "    print(\"\\n=== 4단계: Level 2 메타모델 학습 ===\")\n",
    "    \n",
    "    # 메타피쳐 결합\n",
    "    meta_features_train = pd.concat([\n",
    "        oof_predictions, \n",
    "        building_meta_train_df,\n",
    "        train_data[['건물번호', 'hour', 'dow', 'month']].reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "    \n",
    "    meta_features_test = pd.concat([\n",
    "        test_predictions,\n",
    "        building_meta_test_df, \n",
    "        test_data[['건물번호', 'hour', 'dow', 'month']].reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "    \n",
    "    print(f\"메타피쳐 수: {len(meta_features_train.columns)}\")\n",
    "    \n",
    "    # 메타모델들 (GPU 설정 재확인)\n",
    "    meta_models = {\n",
    "        'ridge': Ridge(alpha=1.0),\n",
    "        'rf_meta': RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42, n_jobs=-1),\n",
    "        'xgb_meta': xgb.XGBRegressor(\n",
    "            n_estimators=300, max_depth=4, learning_rate=0.1,\n",
    "            tree_method='gpu_hist', gpu_id=0, \n",
    "            random_state=42, verbosity=0\n",
    "        ),\n",
    "        'lgb_meta': lgb.LGBMRegressor(\n",
    "            n_estimators=300, max_depth=4, learning_rate=0.1,\n",
    "            device='gpu', random_state=42, verbose=-1\n",
    "        ), \n",
    "        'cat_meta': cb.CatBoostRegressor(\n",
    "            iterations=200, depth=4, learning_rate=0.1,\n",
    "            task_type='GPU', random_state=42, verbose=False\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # 메타모델 학습 및 예측\n",
    "    meta_oof = pd.DataFrame(index=train_data.index)\n",
    "    meta_test = pd.DataFrame()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    meta_features_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(meta_features_train), \n",
    "        columns=meta_features_train.columns,\n",
    "        index=meta_features_train.index\n",
    "    )\n",
    "    meta_features_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(meta_features_test),\n",
    "        columns=meta_features_test.columns, \n",
    "        index=meta_features_test.index\n",
    "    )\n",
    "    \n",
    "    for name, meta_model in meta_models.items():\n",
    "        print(f\"Learning meta model {name}...\")\n",
    "        meta_oof_pred = np.zeros(len(meta_features_train_scaled))\n",
    "        meta_test_pred = np.zeros(len(meta_features_test_scaled))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(meta_features_train_scaled)):\n",
    "            X_tr = meta_features_train_scaled.iloc[train_idx]\n",
    "            X_val = meta_features_train_scaled.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            meta_model.fit(X_tr, y_tr)\n",
    "            meta_oof_pred[val_idx] = meta_model.predict(X_val)\n",
    "            meta_test_pred += meta_model.predict(meta_features_test_scaled) / 5\n",
    "        \n",
    "        meta_oof[f'{name}_pred'] = meta_oof_pred\n",
    "        meta_test[f'{name}_pred'] = meta_test_pred\n",
    "        \n",
    "        score = smape(y_train, meta_oof_pred)\n",
    "        print(f\"{name} meta SMAPE: {score:.4f}\")\n",
    "    \n",
    "    # 6. 최종 앙상블 (성능 기반 동적 가중치)\n",
    "    print(\"\\n=== 5단계: 최종 앙상블 ===\")\n",
    "    \n",
    "    # 각 메타모델 성능 수집\n",
    "    meta_scores = {}\n",
    "    for col in meta_oof.columns:\n",
    "        score = smape(y_train, meta_oof[col])\n",
    "        meta_scores[col] = score\n",
    "        print(f\"{col} SMAPE: {score:.4f}\")\n",
    "    \n",
    "    # 성능 기반 가중치 계산 (성능이 좋을수록 높은 가중치)\n",
    "    scores_array = np.array(list(meta_scores.values()))\n",
    "    # 역수를 취해서 낮은 SMAPE가 높은 가중치를 가지도록\n",
    "    inverse_scores = 1 / (scores_array + 1e-8)\n",
    "    weights = inverse_scores / inverse_scores.sum()\n",
    "    \n",
    "    print(f\"동적 가중치: {dict(zip(meta_scores.keys(), weights))}\")\n",
    "    \n",
    "    final_oof = (meta_oof * weights).sum(axis=1)\n",
    "    final_test = (meta_test * weights).sum(axis=1)\n",
    "    \n",
    "    final_score = smape(y_train, final_oof)\n",
    "    print(f\"최종 앙상블 SMAPE: {final_score:.4f}\")\n",
    "    \n",
    "    # Level 1 앙상블과 비교\n",
    "    if final_score > ensemble_score:\n",
    "        print(f\"Level 1 앙상블이 더 좋음. Level 1 사용\")\n",
    "        final_test = test_predictions.mean(axis=1)\n",
    "        final_score = ensemble_score\n",
    "    \n",
    "    # 7. 건물별 개별 모델 (최적 모델 자동 선택)\n",
    "    print(\"\\n=== 6단계: 건물별 개별 모델 ===\")\n",
    "    building_predictions = {}\n",
    "    building_scores = []\n",
    "    building_best_models = {}\n",
    "    \n",
    "    # 건물별 모델 후보군 (GPU 설정 명시적으로)\n",
    "    building_model_candidates = {\n",
    "        'xgb': lambda: xgb.XGBRegressor(\n",
    "            n_estimators=500, max_depth=6, learning_rate=0.05,\n",
    "            subsample=0.9, colsample_bytree=0.8,\n",
    "            tree_method='gpu_hist', gpu_id=0,\n",
    "            early_stopping_rounds=50, random_state=42, verbosity=0\n",
    "        ),\n",
    "        'lgb': lambda: lgb.LGBMRegressor(\n",
    "            n_estimators=500, max_depth=6, learning_rate=0.05,\n",
    "            subsample=0.9, colsample_bytree=0.8,\n",
    "            device='gpu', random_state=42, verbose=-1\n",
    "        ),\n",
    "        'cat': lambda: cb.CatBoostRegressor(\n",
    "            iterations=300, depth=6, learning_rate=0.05,\n",
    "            l2_leaf_reg=3, task_type='GPU',\n",
    "            random_state=42, verbose=False\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    for building_num in tqdm(range(1, 101), desc=\"건물별 모델\"):\n",
    "        building_train = train_data[train_data['건물번호'] == building_num].copy()\n",
    "        building_test = test_data[test_data['건물번호'] == building_num].copy()\n",
    "        \n",
    "        if len(building_train) == 0:\n",
    "            continue\n",
    "        \n",
    "        X_building = building_train[feature_cols]\n",
    "        y_building = building_train['전력소비량(kWh)']\n",
    "        X_test_building = building_test[feature_cols]\n",
    "        \n",
    "        # 80:20 분할\n",
    "        split_point = int(len(X_building) * 0.8)\n",
    "        X_train_b, X_val_b = X_building[:split_point], X_building[split_point:]\n",
    "        y_train_b, y_val_b = y_building[:split_point], y_building[split_point:]\n",
    "        \n",
    "        # 각 모델 성능 비교\n",
    "        best_score = float('inf')\n",
    "        best_model = None\n",
    "        best_model_name = None\n",
    "        \n",
    "        for model_name, model_func in building_model_candidates.items():\n",
    "            try:\n",
    "                model = model_func()\n",
    "                \n",
    "                if model_name in ['xgb']:\n",
    "                    model.fit(X_train_b, y_train_b, \n",
    "                             eval_set=[(X_val_b, y_val_b)], verbose=False)\n",
    "                else:\n",
    "                    model.fit(X_train_b, y_train_b)\n",
    "                \n",
    "                val_pred = model.predict(X_val_b)\n",
    "                score = smape(y_val_b, val_pred)\n",
    "                \n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_model = model\n",
    "                    best_model_name = model_name\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if best_model is not None:\n",
    "            building_scores.append(best_score)\n",
    "            building_best_models[building_num] = best_model_name\n",
    "            \n",
    "            test_pred = best_model.predict(X_test_building)\n",
    "            building_predictions[building_num] = test_pred\n",
    "    \n",
    "    building_avg_score = np.mean(building_scores) if building_scores else final_score\n",
    "    print(f\"건물별 모델 평균 SMAPE: {building_avg_score:.4f}\")\n",
    "    \n",
    "    # 사용된 모델 통계\n",
    "    model_usage = {}\n",
    "    for model_name in building_best_models.values():\n",
    "        model_usage[model_name] = model_usage.get(model_name, 0) + 1\n",
    "    print(f\"건물별 최적 모델 사용 현황: {model_usage}\")\n",
    "    \n",
    "    # 8. 최종 예측 결합 (앙상블 vs 건물별 모델 선택)\n",
    "    print(\"\\n=== 7단계: 최종 예측 결합 ===\")\n",
    "    final_predictions = []\n",
    "    \n",
    "    for idx, row in test_data.iterrows():\n",
    "        building_num = row['건물번호']\n",
    "        \n",
    "        # 건물별 모델 예측값\n",
    "        if building_num in building_predictions:\n",
    "            test_idx = test_data[test_data['건물번호'] == building_num].index.get_loc(idx)\n",
    "            building_pred = building_predictions[building_num][test_idx]\n",
    "        else:\n",
    "            building_pred = final_test.iloc[test_data.index.get_loc(idx)]\n",
    "        \n",
    "        # 앙상블 예측값\n",
    "        ensemble_pred_val = final_test.iloc[test_data.index.get_loc(idx)]\n",
    "        \n",
    "        # 건물별 성능이 앙상블보다 좋으면 건물별 모델 사용\n",
    "        building_score = building_scores[building_num-1] if building_num <= len(building_scores) else final_score\n",
    "        \n",
    "        if building_score < final_score * 0.95:  # 5% 이상 좋으면 건물별 모델\n",
    "            final_pred = building_pred\n",
    "        else:\n",
    "            final_pred = (ensemble_pred_val * 0.7 + building_pred * 0.3)  # 조합\n",
    "        \n",
    "        final_predictions.append({\n",
    "            'num_date_time': row['num_date_time'],\n",
    "            'answer': final_pred\n",
    "        })\n",
    "    \n",
    "    # 9. 제출파일 생성\n",
    "    print(\"\\n=== 8단계: 제출파일 생성 ===\")\n",
    "    submission_df = pd.DataFrame(final_predictions)\n",
    "    submission_df = submission_df.sort_values('num_date_time').reset_index(drop=True)\n",
    "    \n",
    "    # 파일 저장\n",
    "    os.makedirs('../submission', exist_ok=True)\n",
    "    now = datetime.now()\n",
    "    filename = f\"{now.strftime('%Y%m%d_%H%M')}_Advanced_Ensemble_SMAPE_{final_score:.4f}.csv\"\n",
    "    filepath = os.path.join('../submission', filename)\n",
    "    \n",
    "    submission_df.to_csv(filepath, index=False)\n",
    "    \n",
    "    print(f\"\\n=== 최종 결과 ===\")\n",
    "    print(f\"Level 1 앙상블 SMAPE: {ensemble_score:.4f}\")\n",
    "    print(f\"Level 2 메타모델 SMAPE: {final_score:.4f}\")\n",
    "    print(f\"건물별 모델 평균 SMAPE: {building_avg_score:.4f}\")\n",
    "    print(f\"제출파일 저장: {filepath}\")\n",
    "    \n",
    "    return {\n",
    "        'submission_df': submission_df,\n",
    "        'final_score': final_score,\n",
    "        'level1_models': level1_models,\n",
    "        'meta_models': meta_models,\n",
    "        'building_scores': building_scores,\n",
    "        'filepath': filepath\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97020867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220800, 9)\n",
      "['num_date_time', '건물번호', '일시', '기온(°C)', '강수량(mm)', '풍속(m/s)', '습도(%)', '전력소비량(kWh)', 'is_train']\n"
     ]
    }
   ],
   "source": [
    "# 1. 먼저 combined 데이터가 준비되어 있는지 확인\n",
    "print(combined.shape)\n",
    "print(combined.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "964d73c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 분리 및 피처 엔지니어링\n",
    "drop_cols = ['num_date_time', '일시', 'is_train']\n",
    "train_data = combined[combined['is_train']==1].copy()\n",
    "test_data = combined[combined['is_train']==0].copy()\n",
    "\n",
    "train_data = feature_engineering(train_data, is_train=True)\n",
    "test_data = feature_engineering(test_data, is_train=False)\n",
    "train_data, test_data = power_stats_features(train_data, test_data)\n",
    "\n",
    "feature_cols = [col for col in train_data.columns if col not in drop_cols and col != '전력소비량(kWh)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "60215b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPU 사용 확인 ===\n",
      "XGBoost version: 3.0.2\n",
      "LightGBM version: 4.6.0\n",
      "CatBoost version: 1.2.8\n",
      "CUDA available: NVIDIA GeForce GTX 1650\n",
      "=== 1단계: 데이터 준비 ===\n",
      "기본 피처 수: 24\n",
      "\n",
      "=== 2단계: Level 1 모델 학습 ===\n",
      "XGBoost tree_method: gpu_hist\n",
      "LightGBM device: gpu\n",
      "Learning xgb...\n",
      "xgb SMAPE: 5.7418\n",
      "Learning lgb...\n",
      "lgb SMAPE: 5.9409\n",
      "Learning cat...\n",
      "cat SMAPE: 7.9685\n",
      "Learning rf...\n",
      "rf SMAPE: 8.0214\n",
      "\n",
      "Level 1 앙상블 SMAPE: 6.3094\n",
      "\n",
      "=== 3단계: 슈퍼메타피쳐 생성 ===\n",
      "\n",
      "=== 4단계: Level 2 메타모델 학습 ===\n",
      "메타피쳐 수: 16\n",
      "Learning meta model ridge...\n",
      "ridge meta SMAPE: 5.7895\n",
      "Learning meta model rf_meta...\n",
      "rf_meta meta SMAPE: 9.6621\n",
      "Learning meta model xgb_meta...\n",
      "xgb_meta meta SMAPE: 5.0352\n",
      "Learning meta model lgb_meta...\n",
      "lgb_meta meta SMAPE: 5.0560\n",
      "Learning meta model cat_meta...\n",
      "cat_meta meta SMAPE: 5.9555\n",
      "\n",
      "=== 5단계: 최종 앙상블 ===\n",
      "ridge_pred SMAPE: 5.7895\n",
      "rf_meta_pred SMAPE: 9.6621\n",
      "xgb_meta_pred SMAPE: 5.0352\n",
      "lgb_meta_pred SMAPE: 5.0560\n",
      "cat_meta_pred SMAPE: 5.9555\n",
      "동적 가중치: {'ridge_pred': np.float64(0.205498660427877), 'rf_meta_pred': np.float64(0.12313390690257373), 'xgb_meta_pred': np.float64(0.23628392496525866), 'lgb_meta_pred': np.float64(0.23531194366031866), 'cat_meta_pred': np.float64(0.19977156404397203)}\n",
      "최종 앙상블 SMAPE: 5.4334\n",
      "\n",
      "=== 6단계: 건물별 개별 모델 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "건물별 모델: 100%|██████████| 100/100 [06:11<00:00,  3.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "건물별 모델 평균 SMAPE: 6.4778\n",
      "건물별 최적 모델 사용 현황: {'xgb': 35, 'cat': 34, 'lgb': 31}\n",
      "\n",
      "=== 7단계: 최종 예측 결합 ===\n",
      "\n",
      "=== 8단계: 제출파일 생성 ===\n",
      "\n",
      "=== 최종 결과 ===\n",
      "Level 1 앙상블 SMAPE: 6.3094\n",
      "Level 2 메타모델 SMAPE: 5.4334\n",
      "건물별 모델 평균 SMAPE: 6.4778\n",
      "제출파일 저장: ../submission\\20250723_1349_Advanced_Ensemble_SMAPE_5.4334.csv\n"
     ]
    }
   ],
   "source": [
    "# 고급 앙상블 파이프라인 실행\n",
    "results = advanced_ensemble_pipeline(combined, drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4662667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ea337d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_advanced_ensemble_pipeline(combined_data, drop_cols):\n",
    "    \"\"\"개선된 고급 앙상블 파이프라인 - 성능 최적화\"\"\"\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.linear_model import Ridge, ElasticNet\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import KFold\n",
    "    import xgboost as xgb\n",
    "    import lightgbm as lgb\n",
    "    import catboost as cb\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    print(\"=== 개선된 고급 앙상블 파이프라인 ===\")\n",
    "    \n",
    "    # 데이터 준비\n",
    "    print(\"=== 1단계: 데이터 준비 ===\")\n",
    "    train_data = combined_data[combined_data['is_train']==1].copy()\n",
    "    test_data = combined_data[combined_data['is_train']==0].copy()\n",
    "    \n",
    "    train_data = feature_engineering(train_data, is_train=True)\n",
    "    test_data = feature_engineering(test_data, is_train=False)\n",
    "    train_data, test_data = power_stats_features(train_data, test_data)\n",
    "    \n",
    "    feature_cols = [col for col in train_data.columns if col not in drop_cols and col != '전력소비량(kWh)']\n",
    "    print(f\"피처 수: {len(feature_cols)}\")\n",
    "    \n",
    "    # Level 1: 성능 검증된 모델들만 + 최적화된 파라미터\n",
    "    print(\"\\n=== 2단계: Level 1 최적화 모델 학습 ===\")\n",
    "    kf = KFold(n_splits=7, shuffle=True, random_state=42)  # 7-fold로 증가\n",
    "    \n",
    "    level1_models = {\n",
    "        'xgb': xgb.XGBRegressor(\n",
    "            n_estimators=600,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            reg_alpha=0.5,\n",
    "            reg_lambda=0.5,\n",
    "            min_child_weight=5,\n",
    "            tree_method='gpu_hist',\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        ),\n",
    "        'lgb': lgb.LGBMRegressor(\n",
    "            n_estimators=600,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.85,\n",
    "            reg_alpha=0.5,\n",
    "            reg_lambda=0.5,\n",
    "            num_leaves=128,\n",
    "            min_child_samples=80,\n",
    "            device='gpu',\n",
    "            random_state=42,\n",
    "            verbose=-1\n",
    "        ),\n",
    "        'cat': cb.CatBoostRegressor(\n",
    "            iterations=500,\n",
    "            depth=6,\n",
    "            learning_rate=0.05,\n",
    "            l2_leaf_reg=3,\n",
    "            task_type='GPU',\n",
    "            random_state=42,\n",
    "            verbose=False\n",
    "        )\n",
    "        # RandomForest 제거 (성능이 떨어짐)\n",
    "    }\n",
    "    \n",
    "    # Level 1 예측값 저장\n",
    "    oof_predictions = pd.DataFrame(index=train_data.index)\n",
    "    test_predictions = pd.DataFrame()\n",
    "    \n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data['전력소비량(kWh)']\n",
    "    X_test = test_data[feature_cols]\n",
    "    \n",
    "    for name, model in level1_models.items():\n",
    "        print(f\"Learning {name}...\")\n",
    "        oof_pred = np.zeros(len(X_train))\n",
    "        test_pred = np.zeros(len(X_test))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            model.fit(X_tr, y_tr)\n",
    "            oof_pred[val_idx] = model.predict(X_val)\n",
    "            test_pred += model.predict(X_test) / 7  # 7-fold\n",
    "        \n",
    "        oof_predictions[f'{name}_pred'] = oof_pred\n",
    "        test_predictions[f'{name}_pred'] = test_pred\n",
    "        \n",
    "        score = smape(y_train, oof_pred)\n",
    "        print(f\"{name} SMAPE: {score:.4f}\")\n",
    "    \n",
    "    # Level 1 앙상블\n",
    "    ensemble_pred = oof_predictions.mean(axis=1)\n",
    "    ensemble_score = smape(y_train, ensemble_pred)\n",
    "    print(f\"Level 1 앙상블 SMAPE: {ensemble_score:.4f}\")\n",
    "    \n",
    "    # 강화된 메타피쳐 생성\n",
    "    print(\"\\n=== 3단계: 강화된 메타피쳐 생성 ===\")\n",
    "    \n",
    "    # 기본 통계 메타피쳐\n",
    "    oof_predictions['pred_mean'] = oof_predictions.mean(axis=1)\n",
    "    oof_predictions['pred_std'] = oof_predictions.std(axis=1)\n",
    "    oof_predictions['pred_max'] = oof_predictions.max(axis=1)\n",
    "    oof_predictions['pred_min'] = oof_predictions.min(axis=1)\n",
    "    oof_predictions['pred_range'] = oof_predictions['pred_max'] - oof_predictions['pred_min']\n",
    "    \n",
    "    test_predictions['pred_mean'] = test_predictions.mean(axis=1)\n",
    "    test_predictions['pred_std'] = test_predictions.std(axis=1)\n",
    "    test_predictions['pred_max'] = test_predictions.max(axis=1)\n",
    "    test_predictions['pred_min'] = test_predictions.min(axis=1)\n",
    "    test_predictions['pred_range'] = test_predictions['pred_max'] - test_predictions['pred_min']\n",
    "    \n",
    "    # 고급 메타피쳐 (안전하게)\n",
    "    oof_predictions['pred_agreement'] = oof_predictions['pred_range'] / (oof_predictions['pred_mean'] + 1e-8)\n",
    "    oof_predictions['pred_confidence'] = 1 / (oof_predictions['pred_std'] + 1e-8)\n",
    "    \n",
    "    test_predictions['pred_agreement'] = test_predictions['pred_range'] / (test_predictions['pred_mean'] + 1e-8)\n",
    "    test_predictions['pred_confidence'] = 1 / (test_predictions['pred_std'] + 1e-8)\n",
    "    \n",
    "    # Level 2: 다양한 메타모델\n",
    "    print(\"\\n=== 4단계: Level 2 메타모델 ===\")\n",
    "    \n",
    "    # 메타피쳐 결합\n",
    "    meta_features_train = pd.concat([\n",
    "        oof_predictions, \n",
    "        train_data[['건물번호', 'hour', 'dow', 'month']].reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "    \n",
    "    meta_features_test = pd.concat([\n",
    "        test_predictions,\n",
    "        test_data[['건물번호', 'hour', 'dow', 'month']].reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "    \n",
    "    # NaN 처리\n",
    "    meta_features_train = meta_features_train.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    meta_features_test = meta_features_test.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    print(f\"메타피쳐 수: {len(meta_features_train.columns)}\")\n",
    "    \n",
    "    # 성능 검증된 메타모델들\n",
    "    meta_models = {\n",
    "        'ridge1': Ridge(alpha=0.5),\n",
    "        'ridge2': Ridge(alpha=1.0),\n",
    "        'ridge3': Ridge(alpha=2.0),\n",
    "        'elastic': ElasticNet(alpha=1.0, l1_ratio=0.3),\n",
    "        'xgb_meta': xgb.XGBRegressor(\n",
    "            n_estimators=300,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.1,\n",
    "            tree_method='gpu_hist',\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # 메타모델 학습\n",
    "    meta_oof = pd.DataFrame(index=train_data.index)\n",
    "    meta_test = pd.DataFrame()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    meta_features_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(meta_features_train), \n",
    "        columns=meta_features_train.columns,\n",
    "        index=meta_features_train.index\n",
    "    )\n",
    "    meta_features_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(meta_features_test),\n",
    "        columns=meta_features_test.columns, \n",
    "        index=meta_features_test.index\n",
    "    )\n",
    "    \n",
    "    for name, meta_model in meta_models.items():\n",
    "        print(f\"Learning meta model {name}...\")\n",
    "        meta_oof_pred = np.zeros(len(meta_features_train_scaled))\n",
    "        meta_test_pred = np.zeros(len(meta_features_test_scaled))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(meta_features_train_scaled)):\n",
    "            X_tr = meta_features_train_scaled.iloc[train_idx]\n",
    "            X_val = meta_features_train_scaled.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            meta_model.fit(X_tr, y_tr)\n",
    "            meta_oof_pred[val_idx] = meta_model.predict(X_val)\n",
    "            meta_test_pred += meta_model.predict(meta_features_test_scaled) / 7\n",
    "        \n",
    "        meta_oof[f'{name}_pred'] = meta_oof_pred\n",
    "        meta_test[f'{name}_pred'] = meta_test_pred\n",
    "        \n",
    "        score = smape(y_train, meta_oof_pred)\n",
    "        print(f\"{name} meta SMAPE: {score:.4f}\")\n",
    "    \n",
    "    # 최고 성능 메타모델 선택\n",
    "    print(\"\\n=== 5단계: 최고 성능 메타모델 선택 ===\")\n",
    "    \n",
    "    meta_scores = {}\n",
    "    for col in meta_oof.columns:\n",
    "        score = smape(y_train, meta_oof[col])\n",
    "        meta_scores[col] = score\n",
    "    \n",
    "    # 최고 성능 모델 찾기\n",
    "    best_meta_model = min(meta_scores.keys(), key=lambda x: meta_scores[x])\n",
    "    best_meta_score = meta_scores[best_meta_model]\n",
    "    \n",
    "    print(f\"최고 메타모델: {best_meta_model} (SMAPE: {best_meta_score:.4f})\")\n",
    "    print(f\"Level 1 앙상블: {ensemble_score:.4f}\")\n",
    "    \n",
    "    # 최고 성능 선택\n",
    "    if best_meta_score < ensemble_score:\n",
    "        print(f\"메타모델 사용: {best_meta_score:.4f}\")\n",
    "        final_test = meta_test[best_meta_model]\n",
    "        final_score = best_meta_score\n",
    "    else:\n",
    "        print(f\"Level 1 앙상블 사용: {ensemble_score:.4f}\")\n",
    "        final_test = test_predictions.mean(axis=1)\n",
    "        final_score = ensemble_score\n",
    "    \n",
    "    # 제출파일 생성\n",
    "    print(\"\\n=== 6단계: 제출파일 생성 ===\")\n",
    "    \n",
    "    final_predictions = []\n",
    "    for idx, row in test_data.iterrows():\n",
    "        test_row_idx = test_data.index.get_loc(idx)\n",
    "        pred_value = final_test.iloc[test_row_idx]\n",
    "        \n",
    "        final_predictions.append({\n",
    "            'num_date_time': row['num_date_time'],\n",
    "            'answer': pred_value\n",
    "        })\n",
    "    \n",
    "    submission_df = pd.DataFrame(final_predictions)\n",
    "    submission_df = submission_df.sort_values('num_date_time').reset_index(drop=True)\n",
    "    \n",
    "    # 파일 저장\n",
    "    os.makedirs('../submission', exist_ok=True)\n",
    "    now = datetime.now()\n",
    "    filename = f\"{now.strftime('%Y%m%d_%H%M')}_Improved_Advanced_SMAPE_{final_score:.4f}.csv\"\n",
    "    filepath = os.path.join('../submission', filename)\n",
    "    \n",
    "    submission_df.to_csv(filepath, index=False)\n",
    "    \n",
    "    print(f\"\\n=== 최종 결과 ===\")\n",
    "    print(f\"최종 SMAPE: {final_score:.4f}\")\n",
    "    print(f\"제출파일 저장: {filepath}\")\n",
    "    \n",
    "    return {\n",
    "        'submission_df': submission_df,\n",
    "        'final_score': final_score,\n",
    "        'level1_models': level1_models,\n",
    "        'meta_models': meta_models,\n",
    "        'filepath': filepath\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "996145d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 개선된 고급 앙상블 파이프라인 ===\n",
      "=== 1단계: 데이터 준비 ===\n",
      "피처 수: 24\n",
      "\n",
      "=== 2단계: Level 1 최적화 모델 학습 ===\n",
      "Learning xgb...\n",
      "xgb SMAPE: 5.2632\n",
      "Learning lgb...\n",
      "lgb SMAPE: 5.8264\n",
      "Learning cat...\n",
      "cat SMAPE: 8.3109\n",
      "Level 1 앙상블 SMAPE: 6.1449\n",
      "\n",
      "=== 3단계: 강화된 메타피쳐 생성 ===\n",
      "\n",
      "=== 4단계: Level 2 메타모델 ===\n",
      "메타피쳐 수: 14\n",
      "Learning meta model ridge1...\n",
      "ridge1 meta SMAPE: 5.2887\n",
      "Learning meta model ridge2...\n",
      "ridge2 meta SMAPE: 5.2869\n",
      "Learning meta model ridge3...\n",
      "ridge3 meta SMAPE: 5.2845\n",
      "Learning meta model elastic...\n",
      "elastic meta SMAPE: 16.4648\n",
      "Learning meta model xgb_meta...\n",
      "xgb_meta meta SMAPE: 5.1870\n",
      "\n",
      "=== 5단계: 최고 성능 메타모델 선택 ===\n",
      "최고 메타모델: xgb_meta_pred (SMAPE: 5.1870)\n",
      "Level 1 앙상블: 6.1449\n",
      "메타모델 사용: 5.1870\n",
      "\n",
      "=== 6단계: 제출파일 생성 ===\n",
      "\n",
      "=== 최종 결과 ===\n",
      "최종 SMAPE: 5.1870\n",
      "제출파일 저장: ../submission\\20250723_1355_Improved_Advanced_SMAPE_5.1870.csv\n"
     ]
    }
   ],
   "source": [
    "results = improved_advanced_ensemble_pipeline(combined, drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c8200dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfect_optuna_tuning(combined_data, drop_cols, n_trials=100):\n",
    "    \"\"\"과적합 방지 + 안정성 보장하는 완벽한 Optuna 튜닝\"\"\"\n",
    "    import optuna\n",
    "    from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "    import xgboost as xgb\n",
    "    import lightgbm as lgb\n",
    "    import catboost as cb\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    print(\"=== 완벽한 Optuna 하이퍼파라미터 튜닝 ===\")\n",
    "    \n",
    "    # 데이터 준비\n",
    "    train_data = combined_data[combined_data['is_train']==1].copy()\n",
    "    train_data = feature_engineering(train_data, is_train=True)\n",
    "    train_data, _ = power_stats_features(train_data, train_data)\n",
    "    \n",
    "    feature_cols = [col for col in train_data.columns if col not in drop_cols and col != '전력소비량(kWh)']\n",
    "    X = train_data[feature_cols]\n",
    "    y = train_data['전력소비량(kWh)']\n",
    "    \n",
    "    print(f\"데이터 크기: {X.shape}\")\n",
    "    print(f\"피처 수: {len(feature_cols)}\")\n",
    "    \n",
    "    # 안정적인 CV 전략 (건물번호 기반 stratified)\n",
    "    def get_cv_folds():\n",
    "        # 건물번호별로 균등하게 분할\n",
    "        building_groups = train_data['건물번호'].values\n",
    "        from sklearn.model_selection import GroupKFold\n",
    "        cv = GroupKFold(n_splits=5)\n",
    "        return list(cv.split(X, y, groups=building_groups))\n",
    "    \n",
    "    cv_folds = get_cv_folds()\n",
    "    \n",
    "    # XGBoost 최적화 (안전한 범위)\n",
    "    def xgb_objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 300, 800),  # 적당한 범위\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 8),           # 과적합 방지\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.15),  # 안전한 범위\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 0.9),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 0.9),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.5, 3.0),     # 정규화 강화\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.5, 3.0),   # 정규화 강화\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 3, 10),\n",
    "            'tree_method': 'gpu_hist',\n",
    "            'random_state': 42,\n",
    "            'verbosity': 0\n",
    "        }\n",
    "        \n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        \n",
    "        # 안정적인 CV 평가\n",
    "        cv_scores = []\n",
    "        for train_idx, val_idx in cv_folds:\n",
    "            X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            model.fit(X_tr, y_tr)\n",
    "            pred = model.predict(X_val)\n",
    "            score = smape(y_val, pred)\n",
    "            cv_scores.append(score)\n",
    "        \n",
    "        # 평균 + 표준편차로 안정성 고려\n",
    "        mean_score = np.mean(cv_scores)\n",
    "        std_score = np.std(cv_scores)\n",
    "        \n",
    "        # 표준편차가 큰 경우 패널티 (불안정한 모델 배제)\n",
    "        penalty = std_score * 0.1  # 표준편차에 비례한 패널티\n",
    "        return mean_score + penalty\n",
    "    \n",
    "    # LightGBM 최적화 (안전한 범위)\n",
    "    def lgb_objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 300, 800),\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 8),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.15),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 0.9),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 0.9),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.5, 3.0),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.5, 3.0),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 31, 255),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 20, 100),\n",
    "            'device': 'gpu',\n",
    "            'random_state': 42,\n",
    "            'verbose': -1\n",
    "        }\n",
    "        \n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        \n",
    "        cv_scores = []\n",
    "        for train_idx, val_idx in cv_folds:\n",
    "            X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            model.fit(X_tr, y_tr)\n",
    "            pred = model.predict(X_val)\n",
    "            score = smape(y_val, pred)\n",
    "            cv_scores.append(score)\n",
    "        \n",
    "        mean_score = np.mean(cv_scores)\n",
    "        std_score = np.std(cv_scores)\n",
    "        penalty = std_score * 0.1\n",
    "        return mean_score + penalty\n",
    "    \n",
    "    # CatBoost 최적화 (안전한 범위)\n",
    "    def cat_objective(trial):\n",
    "        params = {\n",
    "            'iterations': trial.suggest_int('iterations', 200, 600),\n",
    "            'depth': trial.suggest_int('depth', 4, 8),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.15),\n",
    "            'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n",
    "            'border_count': trial.suggest_int('border_count', 32, 128),\n",
    "            'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
    "            'random_strength': trial.suggest_float('random_strength', 0.0, 1.0),\n",
    "            'task_type': 'GPU',\n",
    "            'random_state': 42,\n",
    "            'verbose': False\n",
    "        }\n",
    "        \n",
    "        model = cb.CatBoostRegressor(**params)\n",
    "        \n",
    "        cv_scores = []\n",
    "        for train_idx, val_idx in cv_folds:\n",
    "            X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            model.fit(X_tr, y_tr)\n",
    "            pred = model.predict(X_val)\n",
    "            score = smape(y_val, pred)\n",
    "            cv_scores.append(score)\n",
    "        \n",
    "        mean_score = np.mean(cv_scores)\n",
    "        std_score = np.std(cv_scores)\n",
    "        penalty = std_score * 0.1\n",
    "        return mean_score + penalty\n",
    "    \n",
    "    # 각 모델별 최적화 실행\n",
    "    results = {}\n",
    "    \n",
    "    print(f\"\\n=== XGBoost 최적화 (시도 횟수: {n_trials}) ===\")\n",
    "    study_xgb = optuna.create_study(direction='minimize', study_name='xgboost_perfect')\n",
    "    study_xgb.optimize(xgb_objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    best_xgb_params = study_xgb.best_params\n",
    "    best_xgb_score = study_xgb.best_value\n",
    "    results['xgb'] = {'params': best_xgb_params, 'score': best_xgb_score}\n",
    "    \n",
    "    print(f\"XGBoost 최고 점수: {best_xgb_score:.4f}\")\n",
    "    print(f\"XGBoost 최적 파라미터: {best_xgb_params}\")\n",
    "    \n",
    "    print(f\"\\n=== LightGBM 최적화 (시도 횟수: {n_trials}) ===\")\n",
    "    study_lgb = optuna.create_study(direction='minimize', study_name='lightgbm_perfect')\n",
    "    study_lgb.optimize(lgb_objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    best_lgb_params = study_lgb.best_params\n",
    "    best_lgb_score = study_lgb.best_value\n",
    "    results['lgb'] = {'params': best_lgb_params, 'score': best_lgb_score}\n",
    "    \n",
    "    print(f\"LightGBM 최고 점수: {best_lgb_score:.4f}\")\n",
    "    print(f\"LightGBM 최적 파라미터: {best_lgb_params}\")\n",
    "    \n",
    "    print(f\"\\n=== CatBoost 최적화 (시도 횟수: {n_trials}) ===\")\n",
    "    study_cat = optuna.create_study(direction='minimize', study_name='catboost_perfect')\n",
    "    study_cat.optimize(cat_objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    best_cat_params = study_cat.best_params\n",
    "    best_cat_score = study_cat.best_value\n",
    "    results['cat'] = {'params': best_cat_params, 'score': best_cat_score}\n",
    "    \n",
    "    print(f\"CatBoost 최고 점수: {best_cat_score:.4f}\")\n",
    "    print(f\"CatBoost 최적 파라미터: {best_cat_params}\")\n",
    "    \n",
    "    # 최종 결과 비교\n",
    "    print(f\"\\n=== 최적화 결과 요약 ===\")\n",
    "    for model_name, result in results.items():\n",
    "        print(f\"{model_name}: {result['score']:.4f}\")\n",
    "    \n",
    "    # 최고 성능 모델 찾기\n",
    "    best_model = min(results.keys(), key=lambda x: results[x]['score'])\n",
    "    print(f\"\\n최고 성능 모델: {best_model} (SMAPE: {results[best_model]['score']:.4f})\")\n",
    "    \n",
    "    # 안정성 검증 (최고 모델로 추가 검증)\n",
    "    print(f\"\\n=== 안정성 검증 ===\")\n",
    "    best_params = results[best_model]['params']\n",
    "    \n",
    "    if best_model == 'xgb':\n",
    "        final_model = xgb.XGBRegressor(**best_params)\n",
    "    elif best_model == 'lgb':\n",
    "        final_model = lgb.LGBMRegressor(**best_params)\n",
    "    else:\n",
    "        final_model = cb.CatBoostRegressor(**best_params)\n",
    "    \n",
    "    # 10-fold 안정성 검증\n",
    "    from sklearn.model_selection import KFold\n",
    "    stability_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    stability_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in stability_cv.split(X):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        final_model.fit(X_tr, y_tr)\n",
    "        pred = final_model.predict(X_val)\n",
    "        score = smape(y_val, pred)\n",
    "        stability_scores.append(score)\n",
    "    \n",
    "    stability_mean = np.mean(stability_scores)\n",
    "    stability_std = np.std(stability_scores)\n",
    "    \n",
    "    print(f\"10-fold 안정성 검증:\")\n",
    "    print(f\"평균 SMAPE: {stability_mean:.4f}\")\n",
    "    print(f\"표준편차: {stability_std:.4f}\")\n",
    "    print(f\"변동계수: {stability_std/stability_mean:.3f}\")\n",
    "    \n",
    "    if stability_std/stability_mean > 0.1:\n",
    "        print(\"⚠️  높은 변동성 감지 - 파라미터 재조정 권장\")\n",
    "    else:\n",
    "        print(\"✅ 안정적인 모델 확인\")\n",
    "    \n",
    "    return {\n",
    "        'results': results,\n",
    "        'best_model': best_model,\n",
    "        'best_params': best_params,\n",
    "        'best_score': results[best_model]['score'],\n",
    "        'stability_mean': stability_mean,\n",
    "        'stability_std': stability_std\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeee489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용법\n",
    "results = perfect_optuna_tuning(combined_data, drop_cols, n_trials=50)\n",
    "print(f\"최고 모델: {results['best_model']}\")\n",
    "print(f\"안정적 성능: {results['stability_mean']:.4f} ± {results['stability_std']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
