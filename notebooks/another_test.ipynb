{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "464f9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic' # 한글 폰트 설정\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import torch #cuda용 \n",
    "import warnings # 경고 메시지 무시\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4fa4425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능: True\n",
      "PyTorch CUDA 버전: 11.8\n",
      "GPU 이름: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"PyTorch CUDA 버전: {torch.version.cuda}\")\n",
    "    print(f\"GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CPU 버전이 설치됨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "754704e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ft 컬럼들:\n",
      "['건물번호', '기온(°C)', '강수량(mm)', '풍속(m/s)', '습도(%)', '전력소비량(kWh)', 'hour', 'day', 'month', 'week', '건물유형', '연면적(m2)', '냉방면적(m2)', '태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)', 'holiday', 'sin_time', 'cos_time']\n",
      "\n",
      "test_ft 컬럼들:\n",
      "['건물번호', '기온(°C)', '강수량(mm)', '풍속(m/s)', '습도(%)', '일조(hr)', '일사(MJ/m2)', '전력소비량(kWh)', 'hour', 'day', 'month', 'week', '건물유형', '연면적(m2)', '냉방면적(m2)', '태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)', 'holiday', 'sin_time', 'cos_time']\n",
      "\n",
      "기온 관련 컬럼: ['기온(°C)']\n",
      "습도 관련 컬럼: ['습도(%)']\n",
      "\n",
      "사용할 컬럼: 기온=기온(°C), 습도=습도(%)\n",
      "최종 train_ft 컬럼들:\n",
      "['건물번호', '기온(°C)', '습도(%)', 'hour', 'day', 'month', 'week', '연면적(m2)', '냉방면적(m2)', '태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)', 'sin_time', 'cos_time', 'THI', 'CDH', 'day_hour_mean', 'month_hour_mean', 'hour_mean', 'hour_std', 'day_hour_std', 'day_hour_median']\n",
      "선택된 컬럼들: ['건물번호', 'hour', 'day', 'month', 'week', '연면적(m2)', '냉방면적(m2)', '태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)', 'sin_time', 'cos_time', 'day_hour_mean', 'month_hour_mean', 'hour_mean', 'hour_std', 'day_hour_std', 'day_hour_median', '기온(°C)', '습도(%)', 'THI', 'CDH']\n",
      "전처리 완료!\n",
      "Train shape: (204000, 40)\n",
      "Test shape: (16800, 40)\n",
      "Target shape: (204000,)\n",
      "\n",
      "머신러닝 학습 준비 완료!\n",
      "X_train shape: (204000, 40)\n",
      "y_train shape: (204000,)\n",
      "X_test shape: (16800, 40)\n",
      "\n",
      "X_train 결측치: 0\n",
      "X_test 결측치: 16800\n",
      "y_train 결측치: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 데이터 로드 및 분할\n",
    "building = pd.read_csv('../data/building_info.csv')\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "\n",
    "# 전체 데이터 합치기\n",
    "all_data = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# train과 test 분리\n",
    "train_df = all_data[all_data['is_train'] == 1].drop('is_train', axis=1)\n",
    "test_df = all_data[all_data['is_train'] == 0].drop('is_train', axis=1)\n",
    "\n",
    "# 시간 특성 생성\n",
    "date = pd.to_datetime(train_df['일시'])\n",
    "train_df['hour'] = date.dt.hour\n",
    "train_df['day'] = date.dt.weekday\n",
    "train_df['month'] = date.dt.month\n",
    "train_df['week'] = date.dt.isocalendar().week\n",
    "\n",
    "date = pd.to_datetime(test_df['일시'])\n",
    "test_df['hour'] = date.dt.hour\n",
    "test_df['day'] = date.dt.weekday\n",
    "test_df['month'] = date.dt.month\n",
    "test_df['week'] = date.dt.isocalendar().week\n",
    "\n",
    "# 건물정보 전처리\n",
    "cols = ['태양광용량(kW)','ESS저장용량(kWh)','PCS용량(kW)']\n",
    "for col in cols:\n",
    "    building[col] = building[col].apply(lambda x: 0 if x == '-' else float(x))\n",
    "\n",
    "# train 데이터 결측치 처리\n",
    "train_ft = train_df.drop(columns=['num_date_time', '일시','일조(hr)', '일사(MJ/m2)'])\n",
    "test_ft = test_df.drop(columns=['num_date_time', '일시'])\n",
    "\n",
    "train_ft['강수량(mm)'] = train_ft['강수량(mm)'].fillna(0)\n",
    "\n",
    "# 풍속 결측치 처리\n",
    "for i in train_ft[train_ft['풍속(m/s)'].isnull()].index:\n",
    "    month = train_ft.iloc[i]['month']\n",
    "    hour = train_ft.iloc[i]['hour']\n",
    "    num = train_ft.iloc[i]['건물번호']\n",
    "    data_mean = train_ft[(train_ft['건물번호']==num)&(train_ft['month']==month) & (train_ft['hour']==hour)]['풍속(m/s)'].describe()['mean']\n",
    "    train_ft.loc[i,'풍속(m/s)'] = data_mean\n",
    "\n",
    "# 습도 결측치 처리\n",
    "for i in train_ft[train_ft['습도(%)'].isnull()].index:\n",
    "    month = train_ft.iloc[i]['month']\n",
    "    hour = train_ft.iloc[i]['hour']\n",
    "    num = train_ft.iloc[i]['건물번호']\n",
    "    data_mean = train_ft[(train_ft['건물번호']==num)&(train_ft['month']==month) & (train_ft['hour']==hour)]['습도(%)'].describe()['mean']\n",
    "    train_ft.loc[i,'습도(%)'] = data_mean\n",
    "\n",
    "# 건물정보 합치기\n",
    "train_ft = train_ft.merge(building, how='left', on='건물번호')\n",
    "test_ft = test_ft.merge(building, how='left', on='건물번호')\n",
    "\n",
    "# 범주형 인코딩\n",
    "conv_dict = dict(zip(list(train_ft['건물유형'].unique()), range(len(train_ft['건물유형'].unique()))))\n",
    "train_ft['건물유형'] = train_ft['건물유형'].map(conv_dict)\n",
    "test_ft['건물유형'] = test_ft['건물유형'].map(conv_dict)\n",
    "\n",
    "# 타겟 생성\n",
    "target = train_df['전력소비량(kWh)']\n",
    "\n",
    "# 공휴일 특성\n",
    "train_ft['holiday'] = train_ft.apply(lambda x: 0 if x['day'] < 5 else 1, axis=1)\n",
    "test_ft['holiday'] = test_ft.apply(lambda x: 0 if x['day'] < 5 else 1, axis=1)\n",
    "\n",
    "# 시간 순환 특성\n",
    "train_ft['sin_time'] = np.sin(2*np.pi*train_ft.hour/24)\n",
    "train_ft['cos_time'] = np.cos(2*np.pi*train_ft.hour/24)\n",
    "test_ft['sin_time'] = np.sin(2*np.pi*test_ft.hour/24)\n",
    "test_ft['cos_time'] = np.cos(2*np.pi*test_ft.hour/24)\n",
    "\n",
    "# 컬럼명 확인 및 디버깅\n",
    "print(\"train_ft 컬럼들:\")\n",
    "print(train_ft.columns.tolist())\n",
    "print(\"\\ntest_ft 컬럼들:\")\n",
    "print(test_ft.columns.tolist())\n",
    "\n",
    "# 가능한 기온 컬럼명들 확인\n",
    "temp_cols = [col for col in train_ft.columns if '기온' in col or 'temp' in col.lower()]\n",
    "humidity_cols = [col for col in train_ft.columns if '습도' in col or 'humid' in col.lower()]\n",
    "\n",
    "print(f\"\\n기온 관련 컬럼: {temp_cols}\")\n",
    "print(f\"습도 관련 컬럼: {humidity_cols}\")\n",
    "\n",
    "# 실제 컬럼명 사용\n",
    "if temp_cols and humidity_cols:\n",
    "    temp_col = temp_cols[0]  # 첫 번째 기온 컬럼\n",
    "    humidity_col = humidity_cols[0]  # 첫 번째 습도 컬럼\n",
    "    \n",
    "    print(f\"\\n사용할 컬럼: 기온={temp_col}, 습도={humidity_col}\")\n",
    "    \n",
    "    # 불쾌지수\n",
    "    train_ft['THI'] = 9/5*train_ft[temp_col] - 0.55*(1-train_ft[humidity_col]/100)*(9/5*train_ft[temp_col]-26)+32\n",
    "    test_ft['THI'] = 9/5*test_ft[temp_col] - 0.55*(1-test_ft[humidity_col]/100)*(9/5*test_ft[temp_col]-26)+32\n",
    "    \n",
    "    train_ft['THI'] = pd.cut(train_ft['THI'], bins=[0, 68, 75, 80, 200], labels=[1,2,3,4])\n",
    "    train_ft['THI'] = train_ft['THI'].astype(int)\n",
    "    test_ft['THI'] = pd.cut(test_ft['THI'], bins=[0, 68, 75, 80, 200], labels=[1,2,3,4])\n",
    "    test_ft['THI'] = test_ft['THI'].astype(int)\n",
    "    \n",
    "    # CDH 함수\n",
    "    def CDH(xs):\n",
    "        ys = []\n",
    "        for i in range(len(xs)):\n",
    "            if i < 11:\n",
    "                ys.append(np.sum(xs[:(i+1)]-26))\n",
    "            else:\n",
    "                ys.append(np.sum(xs[(i-11):(i+1)]-26))\n",
    "        return np.array(ys)\n",
    "    \n",
    "    # CDH 특성 생성\n",
    "    cdhs = np.array([])\n",
    "    for num in range(1, 101, 1):\n",
    "        temp = train_ft[train_ft['건물번호'] == num]\n",
    "        cdh = CDH(temp[temp_col].values)\n",
    "        cdhs = np.concatenate([cdhs, cdh])\n",
    "    train_ft['CDH'] = cdhs\n",
    "    \n",
    "    cdhs = np.array([])\n",
    "    for num in range(1, 101, 1):\n",
    "        temp = test_ft[test_ft['건물번호'] == num]\n",
    "        cdh = CDH(temp[temp_col].values)\n",
    "        cdhs = np.concatenate([cdhs, cdh])\n",
    "    test_ft['CDH'] = cdhs\n",
    "else:\n",
    "    print(\"기온 또는 습도 컬럼을 찾을 수 없습니다. 컬럼명을 직접 확인해주세요.\")\n",
    "\n",
    "# 요일 시간별 사용량 특성들\n",
    "power_mean = pd.pivot_table(train_ft, values='전력소비량(kWh)', index=['건물번호', 'hour', 'day','month'], aggfunc=np.mean).reset_index()\n",
    "power_mean = power_mean.drop_duplicates(subset=['건물번호', 'hour', 'day'], keep='first')\n",
    "\n",
    "train_ft = train_ft.merge(power_mean[['건물번호', 'hour', 'day', '전력소비량(kWh)']], on=['건물번호', 'hour', 'day'], how='left', suffixes=('', '_mean'))\n",
    "train_ft.rename(columns={'전력소비량(kWh)_mean': 'day_hour_mean'}, inplace=True)\n",
    "\n",
    "test_ft = test_ft.merge(power_mean[['건물번호', 'hour', 'day', '전력소비량(kWh)']], on=['건물번호', 'hour', 'day'], how='left', suffixes=('', '_mean'))\n",
    "test_ft.rename(columns={'전력소비량(kWh)': 'day_hour_mean'}, inplace=True)\n",
    "\n",
    "# 월-시간별 평균\n",
    "power_mean = pd.pivot_table(train_ft, values='전력소비량(kWh)', index=['건물번호', 'hour', 'day','month'], aggfunc=np.mean).reset_index()\n",
    "power_mean = power_mean.drop_duplicates(subset=['건물번호', 'hour', 'month'], keep='first')\n",
    "\n",
    "train_ft = train_ft.merge(power_mean[['건물번호', 'hour', 'month', '전력소비량(kWh)']], on=['건물번호', 'hour', 'month'], how='left', suffixes=('', '_mean'))\n",
    "train_ft.rename(columns={'전력소비량(kWh)_mean': 'month_hour_mean'}, inplace=True)\n",
    "\n",
    "test_ft = test_ft.merge(power_mean[['건물번호', 'hour', 'month', '전력소비량(kWh)']], on=['건물번호', 'hour', 'month'], how='left', suffixes=('', '_mean'))\n",
    "test_ft.rename(columns={'전력소비량(kWh)': 'month_hour_mean'}, inplace=True)\n",
    "\n",
    "# 시간별 평균/표준편차/중앙값\n",
    "power_mean = pd.pivot_table(train_ft, values='전력소비량(kWh)', index=['건물번호', 'hour'], aggfunc=np.mean).reset_index()\n",
    "train_ft = train_ft.merge(power_mean[['건물번호', 'hour', '전력소비량(kWh)']], on=['건물번호', 'hour'], how='left', suffixes=('', '_mean'))\n",
    "train_ft.rename(columns={'전력소비량(kWh)_mean': 'hour_mean'}, inplace=True)\n",
    "\n",
    "test_ft = test_ft.merge(power_mean[['건물번호', 'hour', '전력소비량(kWh)']], on=['건물번호', 'hour'], how='left', suffixes=('', '_mean'))\n",
    "test_ft.rename(columns={'전력소비량(kWh)': 'hour_mean'}, inplace=True)\n",
    "\n",
    "power_std = pd.pivot_table(train_ft, values='전력소비량(kWh)', index=['건물번호', 'hour'], aggfunc=np.std).reset_index()\n",
    "train_ft = train_ft.merge(power_std[['건물번호', 'hour', '전력소비량(kWh)']], on=['건물번호', 'hour'], how='left', suffixes=('', '_std'))\n",
    "train_ft.rename(columns={'전력소비량(kWh)_std': 'hour_std'}, inplace=True)\n",
    "\n",
    "test_ft = test_ft.merge(power_std[['건물번호', 'hour', '전력소비량(kWh)']], on=['건물번호', 'hour'], how='left', suffixes=('', '_std'))\n",
    "test_ft.rename(columns={'전력소비량(kWh)': 'hour_std'}, inplace=True)\n",
    "\n",
    "power_std = pd.pivot_table(train_ft, values='전력소비량(kWh)', index=['건물번호', 'hour', 'day'], aggfunc=np.std).reset_index()\n",
    "train_ft = train_ft.merge(power_std[['건물번호', 'hour', 'day', '전력소비량(kWh)']], on=['건물번호', 'hour', 'day'], how='left', suffixes=('', '_std'))\n",
    "train_ft.rename(columns={'전력소비량(kWh)_std': 'day_hour_std'}, inplace=True)\n",
    "\n",
    "test_ft = test_ft.merge(power_std[['건물번호', 'hour', 'day', '전력소비량(kWh)']], on=['건물번호', 'hour', 'day'], how='left', suffixes=('', '_std'))\n",
    "test_ft.rename(columns={'전력소비량(kWh)': 'day_hour_std'}, inplace=True)\n",
    "\n",
    "power_median = pd.pivot_table(train_ft, values='전력소비량(kWh)', index=['건물번호', 'hour', 'day'], aggfunc=np.median).reset_index()\n",
    "train_ft = train_ft.merge(power_median[['건물번호', 'hour', 'day', '전력소비량(kWh)']], on=['건물번호', 'hour', 'day'], how='left', suffixes=('', '_median'))\n",
    "train_ft.rename(columns={'전력소비량(kWh)_median': 'day_hour_median'}, inplace=True)\n",
    "\n",
    "test_ft = test_ft.merge(power_median[['건물번호', 'hour', 'day', '전력소비량(kWh)']], on=['건물번호', 'hour', 'day'], how='left', suffixes=('', '_median'))\n",
    "test_ft.rename(columns={'전력소비량(kWh)': 'day_hour_median'}, inplace=True)\n",
    "\n",
    "# 불필요 컬럼 제거\n",
    "train_ft = train_ft.drop(columns=['holiday', '건물유형', '강수량(mm)', '풍속(m/s)','전력소비량(kWh)'])\n",
    "test_ft = test_ft.drop(columns=['holiday', '건물유형', '강수량(mm)', '풍속(m/s)'])\n",
    "\n",
    "# 실제 존재하는 컬럼만 선택\n",
    "print(\"최종 train_ft 컬럼들:\")\n",
    "print(train_ft.columns.tolist())\n",
    "\n",
    "# 기본 컬럼들\n",
    "base_cols = ['건물번호', 'hour', 'day', 'month', 'week', '연면적(m2)',\n",
    "           '냉방면적(m2)', '태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)', 'sin_time',\n",
    "           'cos_time', 'day_hour_mean', 'month_hour_mean','hour_mean', 'hour_std','day_hour_std',\n",
    "           'day_hour_median']\n",
    "\n",
    "# 실제 존재하는 컬럼만 필터링\n",
    "existing_cols = [col for col in base_cols if col in train_ft.columns]\n",
    "\n",
    "# 기온, 습도, THI, CDH 컬럼 추가 (존재하는 경우만)\n",
    "for col in train_ft.columns:\n",
    "    if any(keyword in col for keyword in ['기온', '습도', 'THI', 'CDH', '이동평균']):\n",
    "        if col not in existing_cols:\n",
    "            existing_cols.append(col)\n",
    "\n",
    "print(f\"선택된 컬럼들: {existing_cols}\")\n",
    "\n",
    "train_ft = train_ft[existing_cols]\n",
    "test_ft = test_ft[existing_cols]\n",
    "\n",
    "train_ft['전력소비량(kWh)'] = train_df['전력소비량(kWh)']\n",
    "\n",
    "# 클러스터링\n",
    "train_ft['holiday'] = train_ft.apply(lambda x: 0 if x['day'] < 5 else 1, axis=1)\n",
    "test_ft['holiday'] = test_ft.apply(lambda x: 0 if x['day'] < 5 else 1, axis=1)\n",
    "\n",
    "weekday_mean = train_ft[train_ft.holiday==0].pivot_table(values='전력소비량(kWh)', index='건물번호', columns='hour', aggfunc='first')\n",
    "weekend_mean = train_ft[train_ft.holiday==1].pivot_table(values='전력소비량(kWh)', index='건물번호', columns='hour', aggfunc='first')\n",
    "\n",
    "tmp = pd.merge(weekday_mean, weekend_mean, how='left', on='건물번호')\n",
    "\n",
    "SEED = 42\n",
    "kmeans = KMeans(n_clusters=5, random_state=SEED, n_init='auto')\n",
    "kmeans.fit(tmp)\n",
    "\n",
    "cluster_ = kmeans.predict(tmp)\n",
    "tmp['cluster'] = cluster_\n",
    "\n",
    "train_ft = train_ft.merge(tmp[['cluster']], how='left', on='건물번호')\n",
    "test_ft = test_ft.merge(tmp[['cluster']], how='left', on='건물번호')\n",
    "\n",
    "train_ft = train_ft.drop(columns=['holiday'])\n",
    "test_ft = test_ft.drop(columns=['holiday'])\n",
    "\n",
    "power_mean = pd.pivot_table(train_ft, values='전력소비량(kWh)', index=['cluster', 'hour', 'day','month'], aggfunc=np.mean).reset_index()\n",
    "power_mean = power_mean.drop_duplicates(subset=['cluster', 'hour', 'day'], keep='first')\n",
    "\n",
    "train_ft = train_ft.merge(power_mean[['cluster', 'hour', 'day', '전력소비량(kWh)']], on=['cluster', 'hour', 'day'], how='left', suffixes=('', '_mean'))\n",
    "train_ft.rename(columns={'전력소비량(kWh)_mean': 'cluster_day_hour_mean'}, inplace=True)\n",
    "\n",
    "test_ft = test_ft.merge(power_mean[['cluster', 'hour', 'day', '전력소비량(kWh)']], on=['cluster', 'hour', 'day'], how='left', suffixes=('', '_mean'))\n",
    "test_ft.rename(columns={'전력소비량(kWh)': 'cluster_day_hour_mean'}, inplace=True)\n",
    "\n",
    "train_ft = train_ft.drop(columns=['전력소비량(kWh)'])\n",
    "\n",
    "# 이동평균 (기온, 습도 컬럼이 있는 경우만)\n",
    "if temp_cols and humidity_cols:\n",
    "    temp_col = temp_cols[0]\n",
    "    humidity_col = humidity_cols[0]\n",
    "    \n",
    "    # 일별 통계 특성 추가\n",
    "    def calculate_day_values(dataframe, target_column, output_column, aggregation_func):\n",
    "        result_dict = {}\n",
    "        grouped_temp = dataframe.groupby(['건물번호', 'month', 'day'])[target_column].agg(aggregation_func)\n",
    "        \n",
    "        for (building, month, day), value in grouped_temp.items():\n",
    "            result_dict.setdefault(building, {}).setdefault(month, {})[day] = value\n",
    "        \n",
    "        dataframe[output_column] = [\n",
    "            result_dict.get(row['건물번호'], {}).get(row['month'], {}).get(row['day'], None)\n",
    "            for _, row in dataframe.iterrows()\n",
    "        ]\n",
    "    \n",
    "    # 일별 기온 통계 추가\n",
    "    calculate_day_values(train_ft, temp_col, 'day_max_temperature', 'max')\n",
    "    calculate_day_values(train_ft, temp_col, 'day_mean_temperature', 'mean')\n",
    "    calculate_day_values(train_ft, temp_col, 'day_min_temperature', 'min')\n",
    "    train_ft['day_temperature_range'] = train_ft['day_max_temperature'] - train_ft['day_min_temperature']\n",
    "    \n",
    "    calculate_day_values(test_ft, temp_col, 'day_max_temperature', 'max')\n",
    "    calculate_day_values(test_ft, temp_col, 'day_mean_temperature', 'mean')\n",
    "    calculate_day_values(test_ft, temp_col, 'day_min_temperature', 'min')\n",
    "    test_ft['day_temperature_range'] = test_ft['day_max_temperature'] - test_ft['day_min_temperature']\n",
    "    \n",
    "    # WCT(체감온도) 변수 추가 - 풍속 컬럼이 있다면\n",
    "    if any('풍속' in col for col in train_ft.columns):\n",
    "        windspeed_col = [col for col in train_ft.columns if '풍속' in col][0]\n",
    "        # 원래 데이터에서 풍속 가져오기 (drop 전)\n",
    "        train_windspeed = train_df['풍속(m/s)']\n",
    "        test_windspeed = test_df['풍속(m/s)']\n",
    "        \n",
    "        train_ft['WCT'] = 13.12 + 0.6125*train_ft[temp_col] - 11.37*(train_windspeed**0.16) + 0.3965*(train_windspeed**0.16)*train_ft[temp_col]\n",
    "        test_ft['WCT'] = 13.12 + 0.6125*test_ft[temp_col] - 11.37*(test_windspeed**0.16) + 0.3965*(test_windspeed**0.16)*test_ft[temp_col]\n",
    "    \n",
    "    # 시간 푸리에 변환 (기존과 다른 방식)\n",
    "    train_ft['sin_hour2'] = np.sin(2 * np.pi * train_ft['hour']/23.0)\n",
    "    train_ft['cos_hour2'] = np.cos(2 * np.pi * train_ft['hour']/23.0)\n",
    "    test_ft['sin_hour2'] = np.sin(2 * np.pi * test_ft['hour']/23.0)\n",
    "    test_ft['cos_hour2'] = np.cos(2 * np.pi * test_ft['hour']/23.0)\n",
    "    \n",
    "    # 날짜 푸리에 변환\n",
    "    train_ft['sin_date'] = -np.sin(2 * np.pi * (train_ft['month']+train_ft['day']/31)/12)\n",
    "    train_ft['cos_date'] = -np.cos(2 * np.pi * (train_ft['month']+train_ft['day']/31)/12)\n",
    "    test_ft['sin_date'] = -np.sin(2 * np.pi * (test_ft['month']+test_ft['day']/31)/12)\n",
    "    test_ft['cos_date'] = -np.cos(2 * np.pi * (test_ft['month']+test_ft['day']/31)/12)\n",
    "    \n",
    "    # 월 푸리에 변환  \n",
    "    train_ft['sin_month'] = -np.sin(2 * np.pi * train_ft['month']/12.0)\n",
    "    train_ft['cos_month'] = -np.cos(2 * np.pi * train_ft['month']/12.0)\n",
    "    test_ft['sin_month'] = -np.sin(2 * np.pi * test_ft['month']/12.0)\n",
    "    test_ft['cos_month'] = -np.cos(2 * np.pi * test_ft['month']/12.0)\n",
    "    \n",
    "    # 요일 푸리에 변환\n",
    "    train_ft['sin_dayofweek'] = -np.sin(2 * np.pi * (train_ft['day']+1)/7.0)\n",
    "    train_ft['cos_dayofweek'] = -np.cos(2 * np.pi * (train_ft['day']+1)/7.0)\n",
    "    test_ft['sin_dayofweek'] = -np.sin(2 * np.pi * (test_ft['day']+1)/7.0)\n",
    "    test_ft['cos_dayofweek'] = -np.cos(2 * np.pi * (test_ft['day']+1)/7.0)\n",
    "    \n",
    "    # 이동평균\n",
    "    window_size = 96\n",
    "    train_ft['기온_4일_이동평균'] = train_ft.groupby('건물번호')[temp_col].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "    train_ft['습도_4일_이동평균'] = train_ft.groupby('건물번호')[humidity_col].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "    \n",
    "    window_size = 168\n",
    "    train_ft['기온_7일_이동평균'] = train_ft.groupby('건물번호')[temp_col].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "    train_ft['습도_7일_이동평균'] = train_ft.groupby('건물번호')[humidity_col].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "    \n",
    "    # 이동평균을 위해 train 데이터를 test에 추가\n",
    "    for i in range(1, 101):\n",
    "        test_ft = pd.concat([train_ft[train_ft['건물번호']==i], test_ft], axis=0)\n",
    "    \n",
    "    window_size = 96\n",
    "    test_ft['기온_4일_이동평균'] = test_ft.groupby('건물번호')[temp_col].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "    test_ft['습도_4일_이동평균'] = test_ft.groupby('건물번호')[humidity_col].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "    \n",
    "    window_size = 168\n",
    "    test_ft['기온_7일_이동평균'] = test_ft.groupby('건물번호')[temp_col].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "    test_ft['습도_7일_이동평균'] = test_ft.groupby('건물번호')[humidity_col].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "    \n",
    "    # 실제 test 데이터만 남기기 (train 길이만큼 제거)\n",
    "    test_ft = test_ft.tail(len(test_df))\n",
    "\n",
    "print(\"전처리 완료!\")\n",
    "print(f\"Train shape: {train_ft.shape}\")\n",
    "print(f\"Test shape: {test_ft.shape}\")\n",
    "print(f\"Target shape: {target.shape}\")\n",
    "\n",
    "# 머신러닝 학습용 데이터 준비\n",
    "X_train = train_ft.copy()\n",
    "y_train = target.copy()\n",
    "X_test = test_ft.copy()\n",
    "\n",
    "print(\"\\n머신러닝 학습 준비 완료!\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")  \n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "# 결측치 확인\n",
    "print(f\"\\nX_train 결측치: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"X_test 결측치: {X_test.isnull().sum().sum()}\")\n",
    "print(f\"y_train 결측치: {y_train.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12fe6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# SMAPE 계산 함수\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"SMAPE (Symmetric Mean Absolute Percentage Error) 계산\"\"\"\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def main_prediction(X_train, y_train, X_test, test_df):\n",
    "    \"\"\"XGBoost + LightGBM 전용 앙상블 파이프라인\"\"\"\n",
    "    \n",
    "    print(\"XGBoost + LightGBM 간단 앙상블 파이프라인 시작...\")\n",
    "    \n",
    "    # 결측치 처리\n",
    "    if X_train.isnull().sum().sum() > 0:\n",
    "        X_train = X_train.fillna(X_train.median())\n",
    "    if X_test.isnull().sum().sum() > 0:\n",
    "        X_test = X_test.fillna(X_train.median())\n",
    "    \n",
    "    # GPU 사용 확인\n",
    "    print(\"=== GPU 사용 확인 ===\")\n",
    "    try:\n",
    "        print(f\"XGBoost version: {xgb.__version__}\")\n",
    "        print(f\"LightGBM version: {lgb.__version__}\")\n",
    "        \n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"CUDA available: {torch.cuda.get_device_name(0)}\")\n",
    "        else:\n",
    "            print(\"CUDA not available - falling back to CPU\")\n",
    "    except Exception as e:\n",
    "        print(f\"GPU 확인 중 오류: {e}\")\n",
    "    \n",
    "    print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "    \n",
    "    # 1. Level 1: XGBoost + LightGBM (5-fold)\n",
    "    print(\"\\n=== Level 1: XGBoost + LightGBM ===\")\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Level 1 모델들\n",
    "    level1_models = {\n",
    "        'xgb': xgb.XGBRegressor(\n",
    "            n_estimators=1000,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            tree_method='gpu_hist',\n",
    "            gpu_id=0,\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        ),\n",
    "        'lgb': lgb.LGBMRegressor(\n",
    "            n_estimators=1000,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            device='gpu',\n",
    "            random_state=42,\n",
    "            verbose=-1\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Level 1 예측값 저장용\n",
    "    oof_predictions = pd.DataFrame(index=X_train.index)\n",
    "    test_predictions = pd.DataFrame()\n",
    "    \n",
    "    for name, model in level1_models.items():\n",
    "        print(f\"Learning {name}...\")\n",
    "        oof_pred = np.zeros(len(X_train))\n",
    "        test_pred = np.zeros(len(X_test))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            # 모델별 특별 처리\n",
    "            if name == 'xgb':\n",
    "                model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "            else:  # lgb\n",
    "                model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], callbacks=[lgb.log_evaluation(0)])\n",
    "            \n",
    "            oof_pred[val_idx] = model.predict(X_val)\n",
    "            test_pred += model.predict(X_test) / 5\n",
    "        \n",
    "        oof_predictions[f'{name}_pred'] = oof_pred\n",
    "        test_predictions[f'{name}_pred'] = test_pred\n",
    "        \n",
    "        score = smape(y_train, oof_pred)\n",
    "        print(f\"{name} SMAPE: {score:.4f}\")\n",
    "    \n",
    "    # Level 1 앙상블 점수\n",
    "    ensemble_pred = oof_predictions.mean(axis=1)\n",
    "    ensemble_score = smape(y_train, ensemble_pred)\n",
    "    print(f\"Level 1 앙상블 SMAPE: {ensemble_score:.4f}\")\n",
    "    \n",
    "    # 2. Level 2: XGBoost + LightGBM 메타모델\n",
    "    print(\"\\n=== Level 2: 메타모델 ===\")\n",
    "    \n",
    "    # 메타피쳐 생성 (간단하게)\n",
    "    meta_features_train = oof_predictions.copy()\n",
    "    meta_features_train['pred_mean'] = oof_predictions.mean(axis=1)\n",
    "    meta_features_train['pred_diff'] = oof_predictions['xgb_pred'] - oof_predictions['lgb_pred']\n",
    "    \n",
    "    meta_features_test = test_predictions.copy()\n",
    "    meta_features_test['pred_mean'] = test_predictions.mean(axis=1)\n",
    "    meta_features_test['pred_diff'] = test_predictions['xgb_pred'] - test_predictions['lgb_pred']\n",
    "    \n",
    "    # 기본 특성 추가 (있는 것만)\n",
    "    basic_features = []\n",
    "    for col in ['건물번호', 'hour', 'day', 'month']:\n",
    "        if col in X_train.columns:\n",
    "            basic_features.append(col)\n",
    "    \n",
    "    if basic_features:\n",
    "        meta_features_train = pd.concat([meta_features_train, X_train[basic_features]], axis=1)\n",
    "        meta_features_test = pd.concat([meta_features_test, X_test[basic_features]], axis=1)\n",
    "    \n",
    "    print(f\"메타피쳐 수: {len(meta_features_train.columns)}\")\n",
    "    \n",
    "    # 메타모델들 (XGBoost + LightGBM만)\n",
    "    meta_models = {\n",
    "        'xgb_meta': xgb.XGBRegressor(\n",
    "            n_estimators=500, \n",
    "            max_depth=4, \n",
    "            learning_rate=0.1,\n",
    "            subsample=0.9, \n",
    "            colsample_bytree=0.9,\n",
    "            tree_method='gpu_hist', \n",
    "            gpu_id=0, \n",
    "            random_state=42, \n",
    "            verbosity=0\n",
    "        ),\n",
    "        'lgb_meta': lgb.LGBMRegressor(\n",
    "            n_estimators=500, \n",
    "            max_depth=4, \n",
    "            learning_rate=0.1,\n",
    "            subsample=0.9, \n",
    "            colsample_bytree=0.9,\n",
    "            device='gpu', \n",
    "            random_state=42, \n",
    "            verbose=-1\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # 메타모델 학습 및 예측\n",
    "    meta_oof = pd.DataFrame(index=X_train.index)\n",
    "    meta_test = pd.DataFrame()\n",
    "    \n",
    "    # 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    meta_features_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(meta_features_train), \n",
    "        columns=meta_features_train.columns,\n",
    "        index=meta_features_train.index\n",
    "    )\n",
    "    meta_features_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(meta_features_test),\n",
    "        columns=meta_features_test.columns, \n",
    "        index=meta_features_test.index\n",
    "    )\n",
    "    \n",
    "    for name, meta_model in meta_models.items():\n",
    "        print(f\"Learning meta model {name}...\")\n",
    "        meta_oof_pred = np.zeros(len(meta_features_train_scaled))\n",
    "        meta_test_pred = np.zeros(len(meta_features_test_scaled))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(meta_features_train_scaled)):\n",
    "            X_tr = meta_features_train_scaled.iloc[train_idx]\n",
    "            X_val = meta_features_train_scaled.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            if 'xgb' in name:\n",
    "                meta_model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "            else:  # lgb\n",
    "                meta_model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], callbacks=[lgb.log_evaluation(0)])\n",
    "            \n",
    "            meta_oof_pred[val_idx] = meta_model.predict(X_val)\n",
    "            meta_test_pred += meta_model.predict(meta_features_test_scaled) / 5\n",
    "        \n",
    "        meta_oof[f'{name}_pred'] = meta_oof_pred\n",
    "        meta_test[f'{name}_pred'] = meta_test_pred\n",
    "        \n",
    "        score = smape(y_train, meta_oof_pred)\n",
    "        print(f\"{name} meta SMAPE: {score:.4f}\")\n",
    "    \n",
    "    # 3. 최종 앙상블 (성능 기반 가중치)\n",
    "    print(\"\\n=== 최종 앙상블 ===\")\n",
    "    \n",
    "    # 각 메타모델 성능 수집\n",
    "    meta_scores = {}\n",
    "    for col in meta_oof.columns:\n",
    "        score = smape(y_train, meta_oof[col])\n",
    "        meta_scores[col] = score\n",
    "        print(f\"{col} SMAPE: {score:.4f}\")\n",
    "    \n",
    "    # 성능 기반 가중치 계산\n",
    "    scores_array = np.array(list(meta_scores.values()))\n",
    "    inverse_scores = 1 / (scores_array + 1e-8)\n",
    "    weights = inverse_scores / inverse_scores.sum()\n",
    "    \n",
    "    print(f\"동적 가중치: {dict(zip(meta_scores.keys(), weights))}\")\n",
    "    \n",
    "    final_oof = (meta_oof * weights).sum(axis=1)\n",
    "    final_test = (meta_test * weights).sum(axis=1)\n",
    "    \n",
    "    final_score = smape(y_train, final_oof)\n",
    "    print(f\"최종 앙상블 SMAPE: {final_score:.4f}\")\n",
    "    \n",
    "    # Level 1 앙상블과 비교\n",
    "    if final_score > ensemble_score:\n",
    "        print(f\"Level 1 앙상블이 더 좋음. Level 1 사용\")\n",
    "        final_test = test_predictions.mean(axis=1)\n",
    "        final_score = ensemble_score\n",
    "    \n",
    "    # 4. 최종 예측값 생성\n",
    "    print(\"\\n=== 최종 예측값 생성 ===\")\n",
    "    \n",
    "    # 음수 예측값 제거\n",
    "    final_predictions = [max(0, pred) for pred in final_test.tolist()]\n",
    "    \n",
    "    # 5. 제출파일 생성\n",
    "    print(\"\\n=== 제출파일 생성 ===\")\n",
    "    \n",
    "    # 제출 DataFrame 생성\n",
    "    submission_df = pd.DataFrame({\n",
    "        'num_date_time': test_df['num_date_time'],\n",
    "        'answer': final_predictions\n",
    "    })\n",
    "    \n",
    "    # 파일 저장\n",
    "    os.makedirs('../submission', exist_ok=True)\n",
    "    now = datetime.now()\n",
    "    filename = f\"{now.strftime('%Y%m%d_%H%M')}_XGB_LGB_Simple_SMAPE_{final_score:.4f}.csv\"\n",
    "    filepath = os.path.join('../submission', filename)\n",
    "    \n",
    "    submission_df.to_csv(filepath, index=False)\n",
    "    \n",
    "    print(f\"\\n=== 최종 결과 ===\")\n",
    "    print(f\"Level 1 앙상블 SMAPE: {ensemble_score:.4f}\")\n",
    "    print(f\"Level 2 메타모델 SMAPE: {final_score:.4f}\")\n",
    "    print(f\"제출파일 저장: {filepath}\")\n",
    "    \n",
    "    return {\n",
    "        'submission_df': submission_df,\n",
    "        'final_score': final_score,\n",
    "        'level1_models': level1_models,\n",
    "        'meta_models': meta_models,\n",
    "        'filepath': filepath\n",
    "    }\n",
    "\n",
    "# 사용법:\n",
    "# result = main_prediction(X_train, y_train, X_test, test_df)\n",
    "# submission = result['submission_df']\n",
    "# print(f\"최종 SMAPE: {result['final_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb5b1e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost + LightGBM 간단 앙상블 파이프라인 시작...\n",
      "=== GPU 사용 확인 ===\n",
      "XGBoost version: 3.0.2\n",
      "LightGBM version: 4.6.0\n",
      "CUDA available: NVIDIA GeForce GTX 1650\n",
      "Train shape: (204000, 40), Test shape: (16800, 40)\n",
      "\n",
      "=== Level 1: XGBoost + LightGBM ===\n",
      "Learning xgb...\n",
      "xgb SMAPE: 4.6531\n",
      "Learning lgb...\n",
      "lgb SMAPE: 5.9317\n",
      "Level 1 앙상블 SMAPE: 5.0575\n",
      "\n",
      "=== Level 2: 메타모델 ===\n",
      "메타피쳐 수: 8\n",
      "Learning meta model xgb_meta...\n",
      "xgb_meta meta SMAPE: 4.5391\n",
      "Learning meta model lgb_meta...\n",
      "lgb_meta meta SMAPE: 4.4418\n",
      "\n",
      "=== 최종 앙상블 ===\n",
      "xgb_meta_pred SMAPE: 4.5391\n",
      "lgb_meta_pred SMAPE: 4.4418\n",
      "동적 가중치: {'xgb_meta_pred': np.float64(0.4945851637801683), 'lgb_meta_pred': np.float64(0.5054148362198316)}\n",
      "최종 앙상블 SMAPE: 4.4490\n",
      "\n",
      "=== 최종 예측값 생성 ===\n",
      "\n",
      "=== 제출파일 생성 ===\n",
      "\n",
      "=== 최종 결과 ===\n",
      "Level 1 앙상블 SMAPE: 5.0575\n",
      "Level 2 메타모델 SMAPE: 4.4490\n",
      "제출파일 저장: ../submission\\20250725_0928_XGB_LGB_Simple_SMAPE_4.4490.csv\n",
      "최종 SMAPE: 4.4490\n"
     ]
    }
   ],
   "source": [
    "# 바로 실행\n",
    "result = main_prediction(X_train, y_train, X_test, test_df)\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"최종 SMAPE: {result['final_score']:.4f}\")\n",
    "submission = result['submission_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# SMAPE 계산 함수\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"SMAPE (Symmetric Mean Absolute Percentage Error) 계산\"\"\"\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def time_aware_preprocessing(train_df, test_df, building):\n",
    "    \"\"\"시간 순서를 지키는 전처리 - 개선된 버전\"\"\"\n",
    "    print(\"=== 시간 순서 준수 전처리 (개선) ===\")\n",
    "    \n",
    "    # 대회 기준 시점: 2024년 8월 24일 23:59:59\n",
    "    cutoff_date = pd.to_datetime('2024-08-24 23:59:59')\n",
    "    \n",
    "    # 시간 컬럼 변환\n",
    "    train_df['일시'] = pd.to_datetime(train_df['일시'])\n",
    "    test_df['일시'] = pd.to_datetime(test_df['일시'])\n",
    "    \n",
    "    # 기준 시점 이후 데이터 체크\n",
    "    future_data_in_train = train_df[train_df['일시'] > cutoff_date]\n",
    "    if len(future_data_in_train) > 0:\n",
    "        print(f\"⚠️ Train에서 미래 데이터 {len(future_data_in_train)}개 발견 - 제거\")\n",
    "        train_df = train_df[train_df['일시'] <= cutoff_date]\n",
    "    \n",
    "    print(f\"Train 데이터 기간: {train_df['일시'].min()} ~ {train_df['일시'].max()}\")\n",
    "    print(f\"Test 데이터 기간: {test_df['일시'].min()} ~ {test_df['일시'].max()}\")\n",
    "    \n",
    "    # 시간 피처 생성 (더 풍부하게)\n",
    "    for df in [train_df, test_df]:\n",
    "        df['hour'] = df['일시'].dt.hour\n",
    "        df['day'] = df['일시'].dt.weekday\n",
    "        df['month'] = df['일시'].dt.month\n",
    "        df['week'] = df['일시'].dt.isocalendar().week\n",
    "        df['day_of_month'] = df['일시'].dt.day\n",
    "        \n",
    "        # 순환 피처 (더 다양하게)\n",
    "        df['sin_hour'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "        df['cos_hour'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "        df['sin_day'] = np.sin(2 * np.pi * df['day'] / 7)\n",
    "        df['cos_day'] = np.cos(2 * np.pi * df['day'] / 7)\n",
    "        df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "        df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "        df['sin_week'] = np.sin(2 * np.pi * df['week'] / 52)\n",
    "        df['cos_week'] = np.cos(2 * np.pi * df['week'] / 52)\n",
    "        \n",
    "        # 시간대 구분 (더 세밀하게)\n",
    "        df['is_weekend'] = (df['day'] >= 5).astype(int)\n",
    "        df['is_morning'] = ((df['hour'] >= 6) & (df['hour'] < 12)).astype(int)\n",
    "        df['is_afternoon'] = ((df['hour'] >= 12) & (df['hour'] < 18)).astype(int)\n",
    "        df['is_evening'] = ((df['hour'] >= 18) & (df['hour'] < 24)).astype(int)\n",
    "        df['is_night'] = ((df['hour'] >= 0) & (df['hour'] < 6)).astype(int)\n",
    "        \n",
    "        # 계절성\n",
    "        df['is_summer'] = ((df['month'] >= 6) & (df['month'] <= 8)).astype(int)\n",
    "        df['is_winter'] = ((df['month'] == 12) | (df['month'] <= 2)).astype(int)\n",
    "        \n",
    "        # 업무시간\n",
    "        df['is_business_hour'] = ((df['hour'] >= 9) & (df['hour'] <= 18) & (df['day'] < 5)).astype(int)\n",
    "    \n",
    "    # 날씨 파생 피처 (규칙 준수)\n",
    "    for df in [train_df, test_df]:\n",
    "        if '기온(C)' in df.columns:\n",
    "            # 불쾌지수 (THI)\n",
    "            if '습도(%)' in df.columns:\n",
    "                df['THI'] = 9/5*df['기온(C)'] - 0.55*(1-df['습도(%)']/100)*(9/5*df['기온(C)']-26)+32\n",
    "                df['THI_high'] = (df['THI'] > 80).astype(int)\n",
    "                df['THI_low'] = (df['THI'] < 68).astype(int)\n",
    "            \n",
    "            # 온도 구간\n",
    "            df['temp_very_hot'] = (df['기온(C)'] > 30).astype(int)\n",
    "            df['temp_hot'] = ((df['기온(C)'] > 25) & (df['기온(C)'] <= 30)).astype(int)\n",
    "            df['temp_moderate'] = ((df['기온(C)'] > 15) & (df['기온(C)'] <= 25)).astype(int)\n",
    "            df['temp_cold'] = (df['기온(C)'] <= 15).astype(int)\n",
    "        \n",
    "        if '습도(%)' in df.columns:\n",
    "            df['humidity_high'] = (df['습도(%)'] > 70).astype(int)\n",
    "            df['humidity_low'] = (df['습도(%)'] < 40).astype(int)\n",
    "    \n",
    "    # 건물정보 처리 (더 세밀하게)\n",
    "    building_cols = ['태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)']\n",
    "    for col in building_cols:\n",
    "        building[col] = building[col].apply(lambda x: 0 if x == '-' else float(x))\n",
    "    \n",
    "    # 건물 특성 파생변수\n",
    "    building['has_solar'] = (building['태양광용량(kW)'] > 0).astype(int)\n",
    "    building['has_ess'] = (building['ESS저장용량(kWh)'] > 0).astype(int)\n",
    "    building['has_pcs'] = (building['PCS용량(kW)'] > 0).astype(int)\n",
    "    building['energy_self_sufficient'] = (building['has_solar'] & building['has_ess']).astype(int)\n",
    "    \n",
    "    # 건물 크기 구간\n",
    "    building['building_size'] = pd.qcut(building['연면적(m2)'], q=5, labels=[0,1,2,3,4]).astype(int)\n",
    "    building['cooling_ratio'] = building['냉방면적(m2)'] / building['연면적(m2)']\n",
    "    \n",
    "    # 건물유형 인코딩\n",
    "    building_types = building['건물유형'].unique()\n",
    "    building_type_map = {bt: i for i, bt in enumerate(building_types)}\n",
    "    building['건물유형_encoded'] = building['건물유형'].map(building_type_map)\n",
    "    \n",
    "    # 건물정보 병합\n",
    "    train_df = train_df.merge(building, on='건물번호', how='left')\n",
    "    test_df = test_df.merge(building, on='건물번호', how='left')\n",
    "    \n",
    "    # 규칙 준수 통계 피처 (Train 데이터만 사용, 시점 이전)\n",
    "    print(\"=== 규칙 준수 통계 피처 생성 ===\")\n",
    "    \n",
    "    # 건물별 기본 통계 (전체 Train 기간)\n",
    "    building_stats = train_df.groupby('건물번호')['전력소비량(kWh)'].agg([\n",
    "        'mean', 'std', 'min', 'max', 'median'\n",
    "    ]).reset_index()\n",
    "    building_stats.columns = ['건물번호', 'building_power_mean', 'building_power_std', \n",
    "                             'building_power_min', 'building_power_max', 'building_power_median']\n",
    "    \n",
    "    # 건물별 시간대 통계\n",
    "    hourly_stats = train_df.groupby(['건물번호', 'hour'])['전력소비량(kWh)'].mean().reset_index()\n",
    "    hourly_stats.columns = ['건물번호', 'hour', 'building_hour_mean']\n",
    "    \n",
    "    # 건물별 요일 통계\n",
    "    daily_stats = train_df.groupby(['건물번호', 'day'])['전력소비량(kWh)'].mean().reset_index()\n",
    "    daily_stats.columns = ['건물번호', 'day', 'building_day_mean']\n",
    "    \n",
    "    # 통계 피처 병합\n",
    "    for df in [train_df, test_df]:\n",
    "        df = df.merge(building_stats, on='건물번호', how='left')\n",
    "        df = df.merge(hourly_stats, on=['건물번호', 'hour'], how='left')\n",
    "        df = df.merge(daily_stats, on=['건물번호', 'day'], how='left')\n",
    "    \n",
    "    # 전체 통계 (건물 상관없이)\n",
    "    overall_hourly = train_df.groupby('hour')['전력소비량(kWh)'].mean().reset_index()\n",
    "    overall_hourly.columns = ['hour', 'overall_hour_mean']\n",
    "    \n",
    "    overall_daily = train_df.groupby('day')['전력소비량(kWh)'].mean().reset_index()\n",
    "    overall_daily.columns = ['day', 'overall_day_mean']\n",
    "    \n",
    "    for df in [train_df, test_df]:\n",
    "        df = df.merge(overall_hourly, on='hour', how='left')\n",
    "        df = df.merge(overall_daily, on='day', how='left')\n",
    "    \n",
    "    # 피처 선택\n",
    "    feature_cols = [\n",
    "        '건물번호', 'hour', 'day', 'month', 'week', 'day_of_month',\n",
    "        'sin_hour', 'cos_hour', 'sin_day', 'cos_day', 'sin_month', 'cos_month', 'sin_week', 'cos_week',\n",
    "        'is_weekend', 'is_morning', 'is_afternoon', 'is_evening', 'is_night',\n",
    "        'is_summer', 'is_winter', 'is_business_hour',\n",
    "        '기온(C)', '습도(%)', 'THI', 'THI_high', 'THI_low',\n",
    "        'temp_very_hot', 'temp_hot', 'temp_moderate', 'temp_cold',\n",
    "        'humidity_high', 'humidity_low',\n",
    "        '연면적(m2)', '냉방면적(m2)', '태양광용량(kW)', 'ESS저장용량(kWh)', 'PCS용량(kW)',\n",
    "        'has_solar', 'has_ess', 'has_pcs', 'energy_self_sufficient',\n",
    "        'building_size', 'cooling_ratio', '건물유형_encoded',\n",
    "        'building_power_mean', 'building_power_std', 'building_power_min', 'building_power_max', 'building_power_median',\n",
    "        'building_hour_mean', 'building_day_mean', 'overall_hour_mean', 'overall_day_mean'\n",
    "    ]\n",
    "    \n",
    "    # 존재하는 컬럼만 선택\n",
    "    available_cols = [col for col in feature_cols if col in train_df.columns]\n",
    "    print(f\"사용 가능 피처: {len(available_cols)}개\")\n",
    "    \n",
    "    X_train = train_df[available_cols]\n",
    "    y_train = train_df['전력소비량(kWh)']\n",
    "    X_test = test_df[available_cols]\n",
    "    \n",
    "    # 결측치 처리\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "    \n",
    "    return X_train, y_train, X_test, test_df\n",
    "\n",
    "def time_series_safe_prediction(X_train, y_train, X_test, test_df):\n",
    "    \"\"\"시계열 안전 예측 파이프라인\"\"\"\n",
    "    \n",
    "    print(\"시계열 안전 예측 파이프라인 시작...\")\n",
    "    print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "    \n",
    "    # TimeSeriesSplit 사용 (데이터 누수 방지)\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    # XGBoost + LightGBM 모델\n",
    "    models = {\n",
    "        'xgb': xgb.XGBRegressor(\n",
    "            n_estimators=1000,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            tree_method='gpu_hist',\n",
    "            gpu_id=0,\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        ),\n",
    "        'lgb': lgb.LGBMRegressor(\n",
    "            n_estimators=1000,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            device='gpu',\n",
    "            random_state=42,\n",
    "            verbose=-1\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # 시계열 교차검증으로 성능 측정\n",
    "    print(\"\\n=== 시계열 교차검증 ===\")\n",
    "    cv_scores = {}\n",
    "    test_predictions = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Learning {name}...\")\n",
    "        cv_score_list = []\n",
    "        test_pred_list = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train)):\n",
    "            X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            if name == 'xgb':\n",
    "                model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "            else:\n",
    "                model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], callbacks=[lgb.log_evaluation(0)])\n",
    "            \n",
    "            val_pred = model.predict(X_val)\n",
    "            cv_score = smape(y_val, val_pred)\n",
    "            cv_score_list.append(cv_score)\n",
    "            \n",
    "            test_pred = model.predict(X_test)\n",
    "            test_pred_list.append(test_pred)\n",
    "        \n",
    "        cv_scores[name] = np.mean(cv_score_list)\n",
    "        test_predictions[name] = np.mean(test_pred_list, axis=0)\n",
    "        \n",
    "        print(f\"{name} CV SMAPE: {cv_scores[name]:.4f} (±{np.std(cv_score_list):.4f})\")\n",
    "    \n",
    "    # 단순 앙상블 (성능 기반 가중치)\n",
    "    print(\"\\n=== 앙상블 ===\")\n",
    "    \n",
    "    # 성능이 좋은 모델에 더 높은 가중치\n",
    "    scores = np.array(list(cv_scores.values()))\n",
    "    weights = 1 / (scores + 1e-8)\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    weight_dict = dict(zip(cv_scores.keys(), weights))\n",
    "    print(f\"앙상블 가중치: {weight_dict}\")\n",
    "    \n",
    "    # 최종 예측\n",
    "    final_predictions = sum(test_predictions[name] * weight for name, weight in weight_dict.items())\n",
    "    \n",
    "    # 음수 제거\n",
    "    final_predictions = np.maximum(final_predictions, 0)\n",
    "    \n",
    "    # 앙상블 CV 점수 (추정)\n",
    "    ensemble_score = sum(cv_scores[name] * weight for name, weight in weight_dict.items())\n",
    "    print(f\"앙상블 예상 SMAPE: {ensemble_score:.4f}\")\n",
    "    \n",
    "    # 제출파일 생성\n",
    "    print(\"\\n=== 제출파일 생성 ===\")\n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'num_date_time': test_df['num_date_time'],\n",
    "        'answer': final_predictions\n",
    "    })\n",
    "    \n",
    "    # 파일 저장\n",
    "    os.makedirs('../submission', exist_ok=True)\n",
    "    now = datetime.now()\n",
    "    filename = f\"{now.strftime('%Y%m%d_%H%M')}_TimeSafe_SMAPE_{ensemble_score:.4f}.csv\"\n",
    "    filepath = os.path.join('../submission', filename)\n",
    "    \n",
    "    submission_df.to_csv(filepath, index=False)\n",
    "    \n",
    "    print(f\"\\n=== 최종 결과 ===\")\n",
    "    print(f\"시계열 안전 SMAPE: {ensemble_score:.4f}\")\n",
    "    print(f\"제출파일 저장: {filepath}\")\n",
    "    print(f\"데이터 누수 없음 ✅\")\n",
    "    \n",
    "    return {\n",
    "        'submission_df': submission_df,\n",
    "        'final_score': ensemble_score,\n",
    "        'cv_scores': cv_scores,\n",
    "        'filepath': filepath\n",
    "    }\n",
    "\n",
    "# 사용법\n",
    "def safe_main_prediction(train_df, test_df, building):\n",
    "    \"\"\"데이터 누수 없는 안전한 예측\"\"\"\n",
    "    \n",
    "    # 1. 시간 순서를 지키는 전처리\n",
    "    X_train, y_train, X_test, test_df = time_aware_preprocessing(train_df, test_df, building)\n",
    "    \n",
    "    # 2. 시계열 안전 예측\n",
    "    result = time_series_safe_prediction(X_train, y_train, X_test, test_df)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 사용법:\n",
    "# result = safe_main_prediction(train_df, test_df, building)\n",
    "# submission = result['submission_df']\n",
    "# print(f\"안전한 SMAPE: {result['final_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127e974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 시간 순서 준수 전처리 ===\n",
      "Train 데이터 기간: 2024-06-01 00:00:00 ~ 2024-08-24 23:00:00\n",
      "Test 데이터 기간: 2024-08-25 00:00:00 ~ 2024-08-31 23:00:00\n",
      "사용 가능 피처: 19개\n",
      "시계열 안전 예측 파이프라인 시작...\n",
      "Train shape: (204000, 19), Test shape: (16800, 19)\n",
      "\n",
      "=== 시계열 교차검증 ===\n",
      "Learning xgb...\n"
     ]
    }
   ],
   "source": [
    "# 개선된 버전 실행\n",
    "result = safe_main_prediction(train_df, test_df, building)\n",
    "print(f\"개선된 SMAPE: {result['final_score']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
